\documentclass[11pt]{article}
\input{\string~/.macros}
\usepackage[a4paper, total={7in, 9in}]{geometry}
\usepackage{bm}
\usepackage{datetime}
\usepackage{accents}
\usepackage{bbm}
\usepackage{graphicx}
    \graphicspath{{./assets/}{../assets/}}
\usepackage{hyperref}
    \hypersetup{colorlinks=true, linktoc=all, linkcolor=blue, citecolor=red}
\usepackage[backend=biber,sorting=none]{biblatex}
    \addbibresource{references.bib}
    \addbibresource{structured_light.bib}


\setcounter{MaxMatrixCols}{30}
 

\renewcommand{\vec}[1]{vec\left(#1\right)}
\renewcommand{\si}{\boldsymbol{i}}
\renewcommand{\sI}{\boldsymbol{I}}
\newcommand{\wsI}{\widetilde{\boldsymbol{I}}}
\renewcommand{\diag}{\mathbf{diag}}
\newcommand{\minimize}{\text{minimize}\quad}
\newcommand{\subjectto}{\text{subject to}\quad}
\newcommand{\prox}{\textsf{prox}}

\newcommand\ry{\ensuremath{\mathsf{y}}}
\newcommand\rx{\ensuremath{\mathsf{x}}}
\newcommand\rb{\ensuremath{\mathsf{b}}}
\newcommand\rn{\ensuremath{\mathsf{n}}}

\renewcommand\bmu{\ensuremath{\boldsymbol{\mu}}}
\newcommand\bSigma{\ensuremath{\boldsymbol{\Sigma}}}


\usepackage{subfiles} 


\title{Project Report}
\author{Peiqi Wang}


\begin{document}

\maketitle
\newpage 
\tableofcontents
\newpage


\section{Abstract}
We aim to improve upon low level image proecssing pipeline for the coded two-bucket camera. Specifically, we aim to jointly upsample, demultiplex, and denoise two-bucket images to produce full resolution images under different illumination conditions for downstream reconstruction tasks.

\subfile{camera/summary}



\section{Methods}


\subsection{Optimization Problem}

Assuming an isotropic Gaussian noise model ($\by=\bA\bx + \be$ where $\be\sim \sN(0,\sigma^2 \bI)$), and prior $p_{\rx}(x) \propto \exp\pc{ (\lambda/\sigma^2) \rho(\bx) }$ where $\rho:\R^{SP}\to\R$ is some regularizer for $\bx$. Given noisy measurement $\by$, \textit{max a posterior} estimate $\hat{\bx}$ can be obtained by solving the following
\begin{align}
    \text{minimize}\;
        \frac{1}{2} \norm{\bA\bx-\by}_2^2 + \lambda \rho(\bx)
    \label{eq:generic_inverse_problem}
\end{align}

\subsection{Solving Inverse Problem using RED}

To integrate model-based optiimzation and recent advances in learning-based method, plug-and-play (PnP) prior enforces implicit prior by using state of art denoiser to solve the subproblem within iterative methods like ADMM and PGM \cite{venkatakrishnanPlugandPlayPriorsModel2013}. RED derived an explicit form for the prior $\rho$ that give rise to PnP method \cite{romanoLittleEngineThat2016}. Here we use RED to solve (\ref{eq:generic_inverse_problem}).


$ $\\
We first note that the illumination ratios are albedo quasi-invariant, and therefore smooth within object boundaries. Therefore, total variation regularization on illuination ratio images could be particularly effective. To avoid extra notations, we use $\bx,\by$ as the corresponding illumination ratios that we want to reconstruct. Additionally, we adapt algorithm in \cite{romanoLittleEngineThat2016} for imposing algorithm induced priors with state-of-the-art denoisers. In summary, we want to optimize the following constrained problem with a set of affine constraints,
\begin{align*}
    \minimize  & \norm{\bA\bx_1 - \by}_2^2 + \frac{\lambda_2}{2} \bx_2^T(\bx_2 - \sD(\bx_2)) + \lambda_3 \norm{\bx_3}_1 \\
    \subjectto & \bx_1 - \bx_2 = 0 \\
               & \bG\bx_1 - \bx_3 = 0 \\
\end{align*}
where $\bx_1,\bx_2\in\R^{SP}$, $\bx_3\in\R^{2SP}$. $\lambda_2,\lambda_3>0$ are weights to the regularizers. $\bG\in \R^{2SP\times SP}$ is the discrete image gradient for $S$ images 
\[
    \bG =
    \begin{bmatrix}
        \bI_S \otimes \bG_x \\
        \bI_S \otimes \bG_y \\
    \end{bmatrix} 
\]
where $\bG_x,\bG_y\in\R^{P\times P}$ are the discrete image gradients for a single image computed using forward difference. We can gather constraints into a single linear system 
\[
    \bH\bx = 0
    \quad\quad \text{where}\quad\quad
    \bH = 
    \begin{bmatrix}
        \bI_{SP} & -\bI_{SP} & 0  \\
        \bG    & 0    & -\bI_{SP}  \\
    \end{bmatrix}
    \quad
    \bx = 
    \begin{bmatrix}
        \bx_1 \\ \bx_2 \\ \bx_3
    \end{bmatrix}
\]
and arrive at an equivalent optimization problem
\begin{equation}
    \label{eq:method_optimization_problem}
    \begin{aligned}
        \minimize  & f_1(\bx_1) + \lambda_2 f_2(\bx_2) + \lambda_3 f_3(\bx_3) \\
        \subjectto & (\bx_1,\bx_2,\bx_3) \in \sC
    \end{aligned}
\end{equation}
where $\sC = \{\bx\in\R^{4SP} \;\mid\; \bH\bx = 0\}$ and 
\begin{align*}
    f_1(\bx_1)
        &=\norm{\bA\bx_1 - \by}_2^2 \\
    f_2(\bx_2)
        &=\frac{1}{2} \bx_2^T(\bx_2 - \sD(\bx_2)) \\
    f_3(\bx_3)
        &=\norm{\bx_3}_1
\end{align*}

\subsection{Optimization}

As shown below, the scaled form ADMM for solving (\ref{eq:method_optimization_problem}) is given by 
\begin{align*}
    \bx_1^{k+1}
        &= \prox_{(1/\rho)f_1}(\bz_1^k - \bu_1^k) 
        = (I + \frac{2}{\rho} A^TA)^{-1} ( \bz_1^k - \bu_1^k + \frac{2}{\rho}A^T y) \\
    \bx_2^{k+1}
        &= \prox_{(\lambda_2/\rho)f_2}(\bz_2^k - \bu_2^k) 
        = \frac{1}{\lambda_2+\rho} (\lambda_2 \sD(\bx_2^k) + \rho(\bz_2^k - \bu_2^k)) \\
    \bx_3^{k+1}
        &= \prox_{(\lambda_3/\rho)f_3} (\bz_3^k - \bu_3^k) 
        = \sS_{\lambda_3/\rho}(\bz_3^k - \bu_3^k) \\
    \bz^{k+1}
        &= \prox_{(1/\rho)\sI_{\sC}}(\bx^{k+1} + \bu^k)
        = (I - \bH^{\dagger}\bH)(\bx^{k+1}+\bu^k) \\
    \bu^{k+1}
        &= \bu^{k} + \bx^{k+1} - \bz^{k+1}
\end{align*}

 
 
\subfile{details/summary}


\newpage
\printbibliography

\end{document}
