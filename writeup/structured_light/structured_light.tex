\documentclass[11pt]{article}
\input{\string~/.macros}
\usepackage[a4paper, total={7in, 9in}]{geometry}
% \usepackage[a4paper]{geometry}
\usepackage{bm}
\usepackage{accents}
\usepackage{bbm}
\usepackage{graphicx}
\graphicspath{{./assets}}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linktoc=all, linkcolor=blue, citecolor=red}
\usepackage[backend=bibtex,sorting=none]{biblatex}
\addbibresource{references.bib}

\newcommand\ry{\ensuremath{\mathsf{y}}}
\newcommand\rx{\ensuremath{\mathsf{x}}}
\newcommand\rb{\ensuremath{\mathsf{b}}}
\newcommand\rn{\ensuremath{\mathsf{n}}}


\renewcommand\bmu{\ensuremath{\boldsymbol{\mu}}}
\newcommand\bSigma{\ensuremath{\boldsymbol{\Sigma}}}


\begin{document}

\section{Structured Light Coding}

Some relevant reiews are \cite{salviPatternCodificationStrategies2004}.


\subsection{Horn \& Kiryati}

One of early study of optimal structured light coding \cite{hornOptimalStructuredLight1997} generalizes Gray Code \cite{satoThreedimensionalSurfaceMeasurement1985}. The authors draw inspirations from communication theory, where the projector projects unique temporal codes, received at each image plane through a noisy channel and subsequently decoded. Let there be $K$ patterns and $L$ code words, we want to encode $x\in [1:L]$, the indices of vertical light planes, using some encoding sceheme $f:[1:L] \to \R^K$ such that nearest neighbor decoding $\hat{x}(y) = \argmin_{x\in [1:L]} ( f(x)-y )$ of a normalized noisy observation $y\in\R^K$ minimizes the probability of depth estimation error. In particular for the following forward model 
\begin{align*}
    \ry = f(\rx) + \rn
    \quad\quad\text{where}\quad\quad
    \rx 
        &\sim \text{Cat}(1/L) \\
    \rn
        &\sim p_{\rn} \\
    \ry|\rx
        &\sim p_{\rn}(y - f(x))
\end{align*}
We want to solve the following optimization problem,
\begin{align*}
    \text{minimize}_{f}\quad \mathbbm{P}(\text{depth estimation error})
        &= \E_{\rx,\ry} \left[ (x-\hat{x}(y))^2 \right] \\
        &= \sum_{x=1}^L p_{\rx}(x) \int p_{\ry|\rx}(y|x) (x - \hat{x}(y))^2 dy \\
        &\propto \sum_{x=1}^L \int (x-\hat{x}(y))^2 p_{\rn}(y-f(x)) dy
\end{align*}
The paper suggest the use of space filling curves as the encoding function and established that Gray code is a special limiting case of the space filling curve. Note here we assume there is no \textit{mutual illumination}, i.e. there is no interval reflection and so the projected codes $f(x)$ is proportional to observation $y$.


\newpage
\printbibliography

\end{document}
