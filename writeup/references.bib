
@inproceedings{changOneNetworkSolve2017,
  address = {{Venice}},
  title = {One {{Network}} to {{Solve Them All}} \textemdash{} {{Solving Linear Inverse Problems Using Deep Projection Models}}},
  isbn = {978-1-5386-1032-9},
  abstract = {While deep learning methods have achieved state-of-theart performance in many challenging inverse problems like image inpainting and super-resolution, they invariably involve problem-specific training of the networks. Under this approach, each inverse problem requires its own dedicated network. In scenarios where we need to solve a wide variety of problems, e.g., on a mobile camera, it is inefficient and expensive to use these problem-specific networks. On the other hand, traditional methods using analytic signal priors can be used to solve any linear inverse problem; this often comes with a performance that is worse than learning-based methods. In this work, we provide a middle ground between the two kinds of methods \textemdash{} we propose a general framework to train a single deep neural network that solves arbitrary linear inverse problems. We achieve this by training a network that acts as a quasi-projection operator for the set of natural images and show that any linear inverse problem involving natural images can be solved using iterative methods. We empirically show that the proposed framework demonstrates superior performance over traditional methods using wavelet sparsity prior while achieving performance comparable to specially-trained networks on tasks including compressive sensing and pixel-wise inpainting.},
  language = {en},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  publisher = {{IEEE}},
  doi = {10.1109/ICCV.2017.627},
  author = {Chang, J. H. Rick and Li, Chun-Liang and Poczos, Barnabas and Kumar, B. V. K. Vijaya and Sankaranarayanan, Aswin C.},
  month = oct,
  year = {2017},
  pages = {5889-5898},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chang et al_2017_One Network to Solve Them All â€” Solving Linear Inverse Problems Using Deep Projection Models.pdf}
}

@incollection{weiCodedTwoBucketCameras2018,
  address = {{Cham}},
  title = {Coded {{Two}}-{{Bucket Cameras}} for {{Computer Vision}}},
  volume = {11207},
  isbn = {978-3-030-01218-2 978-3-030-01219-9},
  abstract = {We introduce coded two-bucket (C2B) imaging, a new operating principle for computational sensors with applications in active 3D shape estimation and coded-exposure imaging. A C2B sensor modulates the light arriving at each pixel by controlling which of the pixel's two ``buckets'' should integrate it. C2B sensors output two images per video frame\textemdash{}one per bucket\textemdash{}and allow rapid, fully-programmable, per-pixel control of the active bucket. Using these properties as a starting point, we (1) develop an image formation model for these sensors, (2) couple them with programmable light sources to acquire illumination mosaics, i.e., images of a scene under many different illumination conditions whose pixels have been multiplexed and acquired in one shot, and (3) show how to process illumination mosaics to acquire live disparity or normal maps of dynamic scenes at the sensor's native resolution. We present the first experimental demonstration of these capabilities, using a fully-functional C2B camera prototype. Key to this unique prototype is a novel programmable CMOS sensor that we designed from the ground up, fabricated and turned into a working system.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  publisher = {{Springer International Publishing}},
  author = {Wei, Mian and Sarhangnejad, Navid and Xia, Zhengfan and Gusev, Nikita and Katic, Nikola and Genov, Roman and Kutulakos, Kiriakos N.},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  keywords = {c2b,mian},
  pages = {55-73},
  file = {/Users/markwang/DropBox (MIT)/zotero/Wei et al_2018_Coded Two-Bucket Cameras for Computer Vision.pdf},
  doi = {10.1007/978-3-030-01219-9_4}
}

@incollection{dempeOptimalityConditionsSimple1970,
  title = {Optimality {{Conditions}} for a {{Simple Convex Bilevel Programming Problem}}},
  volume = {47},
  abstract = {The problem to find a best solution within the set of optimal solutions of a convex optimization problem is modeled as a bilevel
programming problem. It is shown that regularity conditions like Slater's constraint qualification are never satisfied for
this problem. If the lower-level problem is replaced with its (necessary and sufficient) optimality conditions, it is possible
to derive a necessary optimality condition for the resulting problem. An example is used to show that this condition in not
sufficient even if the initial problem is a convex one. If the lower-level problem is replaced using its optimal value, it
is possible to obtain an optimality condition that is both necessary and sufficient in the convex case.},
  booktitle = {Variational {{Analysis}} and {{Generalized Differentiation}} in {{Optimization}} and {{Control}}},
  author = {Dempe, S and Dinh, N and Dutta, Joydeep},
  month = jan,
  year = {1970},
  keywords = {bilevel},
  pages = {149-161},
  file = {/Users/markwang/DropBox (MIT)/zotero/Dempe et al_1970_Optimality Conditions for a Simple Convex Bilevel Programming Problem.pdf},
  doi = {10.1007/978-1-4419-0437-9_7}
}

@incollection{dempeOptimalityConditionsBilevel2006,
  address = {{Boston, MA}},
  series = {Springer {{Optimization}} and {{Its Applications}}},
  title = {Optimality Conditions for Bilevel Programming Problems},
  isbn = {978-0-387-34221-4},
  abstract = {SummaryFocus in the paper is on optimality conditions for bilevel programming problems. We start with a general condition using tangent cones of the feasible set of the bilevel programming problem to derive such conditions for the optimistic bilevel problem. More precise conditions are obtained if the tangent cone possesses an explicit description as it is possible in the case of linear lower level problems. If the optimal solution of the lower level problem is a PC 1-function, sufficient conditions for a global optimal solution of the optimistic bilevel problem can be formulated. In the second part of the paper relations of the bilevel programming problem to set-valued optimization problems and to mathematical programs with equilibrium constraints are given which can also be used to formulate optimality conditions for the original problem. Finally, a variational inequality approach is described which works well when the involved functions are monotone. It consists in a variational re-formulation of the optimality conditions and looking for a solution of the thus obtained variational inequality among the points satisfying the initial constraints. A penalty function technique is applied to get a sequence of approximate solutions converging to a solution of the original problem with monotone operators.},
  language = {en},
  booktitle = {Optimization with {{Multivalued Mappings}}: {{Theory}}, {{Applications}}, and {{Algorithms}}},
  publisher = {{Springer US}},
  author = {Dempe, Stephan and Kalashnikov, Vyatcheslav V. and Kalashnykova, Nataliya},
  editor = {Dempe, Stephan and Kalashnikov, Vyacheslav},
  year = {2006},
  keywords = {Bilevel Programming,Mathematical Programs with Equilibrium Constraints,Necessary and Sufficient Optimality Conditions,Penalty Function Techniques,Set-valued Optimization,Variational Inequality,bilevel},
  pages = {3-28},
  file = {/Users/markwang/DropBox (MIT)/zotero/Dempe et al_2006_Optimality conditions for bilevel programming problems.pdf},
  doi = {10.1007/0-387-34221-4_1}
}

@article{boydDistributedOptimizationStatistical2011,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  volume = {3},
  issn = {1935-8237},
  abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas\textendash{}Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for {$\mathscr{l}$}1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.},
  number = {1},
  journal = {Found. Trends Mach. Learn.},
  doi = {10.1561/2200000016},
  author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  month = jan,
  year = {2011},
  keywords = {admm,boyd},
  pages = {1--122},
  file = {/Users/markwang/DropBox (MIT)/zotero/Boyd et al_2011_Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf}
}

@unpublished{chambolleFirstorderPrimaldualAlgorithm2010,
  title = {A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging},
  abstract = {We study a first-order primal-dual algorithm for convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions, which is optimal for the complete class of non-smooth problems we are considering in this paper. We further show accelerations of the proposed algorithm to yield optimal rates on easier problems. In particular we show that we can achieve O(1/N{$^2$}) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O(1/e\^N) on problems where both are uniformly convex. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and image segmentation.},
  author = {Chambolle, Antonin and Pock, Thomas},
  month = jun,
  year = {2010},
  keywords = {Convex optimization,Dual approaches,Image reconstruction,Inverse problems,Total variation,primal-dual},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chambolle_Pock_2010_A first-order primal-dual algorithm for convex problems with applications to imaging.pdf}
}

@article{parikhProximalAlgorithms2014,
  title = {Proximal {{Algorithms}}},
  volume = {1},
  issn = {2167-3888},
  abstract = {This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton's method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
  number = {3},
  journal = {Found. Trends Optim.},
  doi = {10.1561/2400000003},
  author = {Parikh, Neal and Boyd, Stephen},
  month = jan,
  year = {2014},
  keywords = {proximal},
  pages = {127--239}
}

@article{wangBregmanAlternatingDirection2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1306.3203},
  primaryClass = {cs, math, stat},
  title = {Bregman {{Alternating Direction Method}} of {{Multipliers}}},
  abstract = {The mirror descent algorithm (MDA) generalizes gradient descent by using a Bregman divergence to replace squared Euclidean distance. In this paper, we similarly generalize the alternating direction method of multipliers (ADMM) to Bregman ADMM (BADMM), which allows the choice of different Bregman divergences to exploit the structure of problems. BADMM provides a unified framework for ADMM and its variants, including generalized ADMM, inexact ADMM and Bethe ADMM. We establish the global convergence and the \$O(1/T)\$ iteration complexity for BADMM. In some cases, BADMM can be faster than ADMM by a factor of \$O(n/\textbackslash{}log(n))\$. In solving the linear program of mass transportation problem, BADMM leads to massive parallelism and can easily run on GPU. BADMM is several times faster than highly optimized commercial software Gurobi.},
  journal = {arXiv:1306.3203 [cs, math, stat]},
  author = {Wang, Huahua and Banerjee, Arindam},
  month = jun,
  year = {2013},
  keywords = {admm,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning,bregman},
  file = {/Users/markwang/DropBox (MIT)/zotero/Wang_Banerjee_2013_Bregman Alternating Direction Method of Multipliers.pdf;/Users/markwang/Zotero/storage/JXSW5WK5/1306.html}
}

@article{goldsteinFastAlternatingDirection2014,
  title = {Fast {{Alternating Direction Optimization Methods}}},
  volume = {7},
  abstract = {Alternating direction methods are a common tool for general mathematical programming and optimization. These methods have become particularly important in the field of variational image processing, which frequently requires the minimization of nondifferentiable objectives. This paper considers accelerated (i.e., fast) variants of two common alternating direction methods: the alternating direction method of multipliers (ADMM) and the alternating minimization algorithm (AMA). The proposed acceleration is of the form first proposed by Nesterov for gradient descent methods. In the case that the objective function is strongly convex, global convergence bounds are provided for both classical and accelerated variants of the methods. Numerical examples are presented to demonstrate the superior performance of the fast methods for a wide variety of problems.},
  number = {3},
  journal = {SIAM Journal on Imaging Sciences},
  doi = {10.1137/120896219},
  author = {Goldstein, T. and O'Donoghue, B. and Setzer, S. and Baraniuk, R.},
  month = jan,
  year = {2014},
  keywords = {admm},
  pages = {1588-1623},
  file = {/Users/markwang/DropBox (MIT)/zotero/Goldstein et al_2014_Fast Alternating Direction Optimization Methods.pdf;/Users/markwang/Zotero/storage/TRJ7VBDT/120896219.html}
}

@article{gouldDifferentiatingParameterizedArgmin2019,
  title = {On {{Differentiating Parameterized Argmin}} and {{Argmax Problems}} with {{Application}} to {{Bi}}-Level {{Optimization}}},
  abstract = {Some recent works in machine learning and computer vision involve the solution of a bilevel optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems, including gradient descent, which is popular with current end-to-end learning approaches. In this technical report we collect some results on differentiating argmin and argmax optimization problems with and without constraints and provide some insightful motivating examples.},
  language = {en},
  author = {Gould, Stephen and Fernando, Basura and Cherian, Anoop and Anderson, Peter and Cruz, Rodrigo Santa and Guo, Edison},
  year = {2019},
  keywords = {bilevel},
  pages = {16},
  file = {/Users/markwang/DropBox (MIT)/zotero/Gould et al_2019_On Diï¬€erentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization.pdf}
}

@incollection{wangProximalDeepStructured2016,
  title = {Proximal {{Deep Structured Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  author = {Wang, Shenlong and Fidler, Sanja and Urtasun, Raquel},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  keywords = {proximal,deep},
  pages = {865--873},
  file = {/Users/markwang/DropBox (MIT)/zotero/Wang et al_2016_Proximal Deep Structured Models.pdf;/Users/markwang/Zotero/storage/9YBZYXPZ/6074-proximal-deep-structured-models.html}
}

@article{sinhaReviewBilevelOptimization2018,
  title = {A {{Review}} on {{Bilevel Optimization}}: {{From Classical}} to {{Evolutionary Approaches}} and {{Applications}}},
  volume = {22},
  issn = {1089-778X},
  shorttitle = {A {{Review}} on {{Bilevel Optimization}}},
  abstract = {Bilevel optimization is defined as a mathematical program, where an optimization problem contains another optimization problem as a constraint. These problems have received significant attention from the mathematical programming community. Only limited work exists on bilevel problems using evolutionary computation techniques; however, recently there has been an increasing interest due to the proliferation of practical applications and the potential of evolutionary algorithms in tackling these problems. This paper provides a comprehensive review on bilevel optimization from the basic principles to solution strategies; both classical and evolutionary. A number of potential application problems are also discussed. To offer the readers insights on the prominent developments in the field of bilevel optimization, we have performed an automated text-analysis of an extended list of papers published on bilevel optimization to date. This paper should motivate evolutionary computation researchers to pay more attention to this practical yet challenging area.},
  number = {2},
  journal = {IEEE Transactions on Evolutionary Computation},
  doi = {10.1109/TEVC.2017.2712906},
  author = {Sinha, A. and Malo, P. and Deb, K.},
  month = apr,
  year = {2018},
  keywords = {bilevel,bilevel optimization,Bilevel optimization,bilevel problems,Decision making,evolutionary algorithms,evolutionary computation,Evolutionary computation,evolutionary computation techniques,Fertilizers,Linear programming,mathematical programming,Mathematical programming,mathematical programming community,optimization problem,potential application problems,Programming,Stackelberg games,text analysis},
  pages = {276-295},
  file = {/Users/markwang/DropBox (MIT)/zotero/Sinha et al_2018_A Review on Bilevel Optimization - From Classical to Evolutionary Approaches and Applications.pdf;/Users/markwang/Zotero/storage/RDV9J8IJ/7942105.html}
}

@article{antonelloProximalGradientAlgorithms2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.01621},
  primaryClass = {eess, math},
  title = {Proximal {{Gradient Algorithms}}: {{Applications}} in {{Signal Processing}}},
  shorttitle = {Proximal {{Gradient Algorithms}}},
  abstract = {Advances in numerical optimization have supported breakthroughs in several areas of signal processing. This paper focuses on the recent enhanced variants of the proximal gradient numerical optimization algorithm, which combine quasi-Newton methods with forward-adjoint oracles to tackle large-scale problems and reduce the computational burden of many applications. These proximal gradient algorithms are here described in an easy-to-understand way, illustrating how they are able to address a wide variety of problems arising in signal processing. A new high-level modeling language is presented which is used to demonstrate the versatility of the presented algorithms in a series of signal processing application examples such as sparse deconvolution, total variation denoising, audio de-clipping and others.},
  journal = {arXiv:1803.01621 [eess, math]},
  author = {Antonello, Niccol{\`o} and Stella, Lorenzo and Patrinos, Panagiotis and {van Waterschoot}, Toon},
  month = mar,
  year = {2018},
  keywords = {proximal,Mathematics - Optimization and Control,D.2,Electrical Engineering and Systems Science - Signal Processing,G.1.6,I.2,signalprocessing},
  file = {/Users/markwang/DropBox (MIT)/zotero/Antonello et al_2018_Proximal Gradient Algorithms - Applications in Signal Processing.pdf;/Users/markwang/Zotero/storage/XN8JQBL2/1803.html}
}

@article{dempeSolutionBilevelOptimization2019,
  title = {Solution of Bilevel Optimization Problems Using the {{KKT}} Approach},
  volume = {0},
  issn = {0233-1934},
  abstract = {Using the Karush\textendash{}Kuhn\textendash{}Tucker conditions for the convex lower level problem, the bilevel optimization problem is transformed into a single-level optimization problem (a mathematical program with complementarity constraints). A regularization approach for the latter problem is formulated which can be used to solve the bilevel optimization problem. This is verified if global or local optimal solutions of the auxiliary problems are computed. Stationary solutions of the auxiliary problems converge to C-stationary solutions of the mathematical program with complementarity constraints.},
  number = {0},
  journal = {Optimization},
  doi = {10.1080/02331934.2019.1581192},
  author = {Dempe, S. and Franke, S.},
  month = mar,
  year = {2019},
  keywords = {bilevel,Bilevel optimization,65K05,90C26,91A65,Karushâ€“Kuhnâ€“Tucker transformation,mathematical program with complementarity constraints},
  pages = {1-19},
  file = {/Users/markwang/DropBox (MIT)/zotero/Dempe_Franke_2019_Solution of bilevel optimization problems using the KKT approach.pdf;/Users/markwang/Zotero/storage/62TTLCZ3/02331934.2019.html}
}

@article{ramanathDemosaickingMethodsBayer2002,
  title = {Demosaicking Methods for {{Bayer}} Color Arrays},
  volume = {11},
  abstract = {Digital Still Color Cameras sample the color spectrum using a monolithic array of color filters overlaid on a charge coupled device array such that each pixel samples only one color band. The resulting mosaic of color samples is processed to produce a high resolution color image such that the values of the color bands not sampled at a certain location are estimated from its neighbors. This process is often referred to as demosaicking. This paper introduces and compares a few commonly used demosaicking methods using error metrics like mean squared error in the RGB color space and perceived error in the CIELAB color space. \textcopyright{} 2002 SPIE and IS\&T.},
  journal = {J. Electronic Imaging},
  doi = {10.1117/1.1484495},
  author = {Ramanath, Rajeev and Snyder, Wesley E. and Bilbro, Griff L. and Sander, William A.},
  year = {2002},
  keywords = {Algorithm,Color image,Color space,Computability in Europe,Demosaicing,Experiment,Image resolution,Mean squared error,Nonlinear system,Norm (social),Pixel,XYZ file format},
  pages = {306-315},
  file = {/Users/markwang/DropBox (MIT)/zotero/Ramanath et al_2002_Demosaicking methods for Bayer color arrays.pdf}
}

@article{narasimhanEnhancingResolutionMultiple2005,
  title = {Enhancing Resolution along Multiple Imaging Dimensions Using Assorted Pixels},
  volume = {27},
  issn = {0162-8828},
  abstract = {Multisampled imaging is a general framework for using pixels on an image detector to simultaneously sample multiple dimensions of imaging (space, time, spectrum, brightness, polarization, etc.). The mosaic of red, green, and blue spectral filters found in most solid-state color cameras is one example of multisampled imaging. We briefly describe how multisampling can be used to explore other dimensions of imaging. Once such an image is captured, smooth reconstructions along the individual dimensions can be obtained using standard interpolation algorithms. Typically, this results in a substantial reduction of resolution (and, hence, image quality). One can extract significantly greater resolution in each dimension by noting that the light fields associated with real scenes have enormous redundancies within them, causing different dimensions to be highly correlated. Hence, multisampled images can be better interpolated using local structural models that are learned offline from a diverse set of training images. The specific type of structural models we use are based on polynomial functions of measured image intensities. They are very effective as well as computationally efficient. We demonstrate the benefits of structural interpolation using three specific applications. These are 1) traditional color imaging with a mosaic of color filters, 2) high dynamic range monochrome imaging using a mosaic of exposure filters, and 3) high dynamic range color imaging using a mosaic of overlapping color and exposure filters.},
  number = {4},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2005.76},
  author = {Narasimhan, S. G. and Nayar, S. K.},
  month = apr,
  year = {2005},
  keywords = {Demosaicing,Image resolution,Pixel,Algorithms,Artificial Intelligence,assorted pixels,Bayer pattern.,Brightness,color,Color,Computer Graphics,Detectors,dynamic range,Dynamic range,Filters,image colour analysis,image enhancement,Image Enhancement,Image Interpretation; Computer-Assisted,image resolution,image sampling,image segmentation,Imaging; Three-Dimensional,Index Terms- Image formation,Information Storage and Retrieval,interpolation,Interpolation,learning,learning (artificial intelligence),multiple imaging dimensions,multisampled imaging,multisampling,Numerical Analysis; Computer-Assisted,Pattern Recognition; Automated,Polarization,range monochrome imaging,Reproducibility of Results,resolution,Sensitivity and Specificity,Signal Processing; Computer-Assisted,Solid state circuits,standard interpolation algorithms,structural models,Subtraction Technique},
  pages = {518-530},
  file = {/Users/markwang/DropBox (MIT)/zotero/Narasimhan_Nayar_2005_Enhancing resolution along multiple imaging dimensions using assorted pixels.pdf;/Users/markwang/Zotero/storage/9HLBJLSW/1401906.html}
}

@inproceedings{malvarHighqualityLinearInterpolation2004,
  title = {High-Quality Linear Interpolation for Demosaicing of {{Bayer}}-Patterned Color Images},
  volume = {3},
  abstract = {This paper introduces a new interpolation technique for demosaicing of color images produced by single-CCD digital cameras. We show that the proposed simple linear filter can lead to an improvement in PSNR of over 5.5 dB when compared to bilinear demosaicing, and about 0.7 dB improvement in R and B interpolation when compared to a recently introduced linear interpolator. The proposed filter also outperforms most nonlinear demosaicing algorithms, without the artifacts due to nonlinear processing, and a much reduced computational complexity.},
  booktitle = {2004 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  doi = {10.1109/ICASSP.2004.1326587},
  author = {Malvar, H. S. and {Li-wei He} and Cutler, R.},
  month = may,
  year = {2004},
  keywords = {Demosaicing,Pixel,Color,image colour analysis,interpolation,Interpolation,Bayer-patterned color images,Charge coupled devices,color image linear interpolation,computational complexity reduction,Digital cameras,image demosaicing,image reconstruction,linear filter,Nonlinear filters,Optical films,Optical filters,Optical sensors,PSNR improvement,R/B interpolation,Sensor arrays,single-CCD digital cameras},
  pages = {iii-485},
  file = {/Users/markwang/DropBox (MIT)/zotero/Malvar et al_2004_High-quality linear interpolation for demosaicing of Bayer-patterned color images.pdf;/Users/markwang/Zotero/storage/JJVX2MR6/1326587.html}
}

@article{chungColorDemosaicingUsing2006,
  title = {Color {{Demosaicing Using Variance}} of {{Color Differences}}},
  volume = {15},
  issn = {1057-7149},
  abstract = {This paper presents an adaptive demosaicing algorithm. Missing green samples are first estimated based on the variances of the color differences along different edge directions. The missing red and blue components are then estimated based on the interpolated green plane. This algorithm can effectively preserve the details in texture regions and, at the same time, it can significantly reduce the color artifacts. As compared with the latest demosaicing algorithms, the proposed algorithm produces the best average demosaicing performance both objectively and subjectively},
  number = {10},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2006.877521},
  author = {Chung, K.- and Chan, Y.-},
  month = oct,
  year = {2006},
  keywords = {Demosaicing,Algorithms,Color,image colour analysis,Image Enhancement,Image Interpretation; Computer-Assisted,Information Storage and Retrieval,interpolation,Interpolation,Digital cameras,Sensor arrays,adaptive demosaicing algorithm,Bayer sampling,color artifact reduction,color demosaicing,color difference variance,color filter array,Colorimetry,Costs,digital camera,Digital filters,edge directions,green plane interpolation,Heuristic algorithms,image denoising,Image sampling,Image sensors,image texture,missing blue component,missing green samples,missing red component,Signal processing algorithms,texture regions},
  pages = {2944-2955},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chung_Chan_2006_Color Demosaicing Using Variance of Color Differences.pdf;/Users/markwang/Zotero/storage/W9LQ366Q/1703585.html}
}

@book{liImageDemosaicingSystematic,
  title = {Image {{Demosaicing}}: {{A Systematic Survey}}},
  shorttitle = {Image {{Demosaicing}}},
  abstract = {Image demosaicing is a problem of interpolating full-resolution color images from so-called color-filter-array (CFA) samples. Among various CFA patterns, Bayer pattern has been the most popular choice and demosaicing of Bayer pattern has attracted renewed interest in recent years partially due to the increased availability of source codes/executables in response to the principle of ``reproducible research''. In this article, we provide a systematic survey of over seventy published works in this field since 1999 (complementary to previous reviews 22, 67). Our review attempts to address important issues to demosaicing and identify fundamental differences among competing approaches. Our findings suggest most existing works belong to the class of sequential demosaicing- i.e., luminance channel is interpolated first and then chrominance channels are reconstructed based on recovered luminance information. We report our comparative study results with a collection of eleven competing algorithms whose source codes or executables are provided by the authors. Our comparison is performed on two data sets: Kodak PhotoCD (popular choice) and IMAX high-quality images (more challenging). While most existing demosaicing algorithms achieve good performance on the Kodak data set, their performance on the IMAX one (images with varying-hue and high-saturation edges) degrades significantly. Such observation suggests the importance of properly addressing the issue of mismatch between assumed model and observation data in demosaicing, which calls for further investigation on issues such as model validation, test data selection and performance evaluation.},
  author = {Li, Xin and Gunturk, Bahadir and Zhang, Lei},
  keywords = {Demosaicing},
  file = {/Users/markwang/DropBox (MIT)/zotero/Li et al_Image Demosaicing - A Systematic Survey.pdf;/Users/markwang/Zotero/storage/YXG8RSTP/summary.html}
}

@article{menonColorImageDemosaicking2011,
  title = {Color Image Demosaicking: {{An}} Overview},
  volume = {26},
  shorttitle = {Color Image Demosaicking},
  abstract = {Demosaicking is the process of reconstructing a full-resolution color image from the sampled data acquired by a digital camera that apply a color filter array to a single sensor. This paper discusses the need of a color filter array and presents a survey of several techniques proposed to demosaicking. A comparison between the different methods is also provided, discussing their performances.},
  journal = {Sig. Proc.: Image Comm.},
  doi = {10.1016/j.image.2011.04.003},
  author = {Menon, Daniele and Calvagno, Giancarlo},
  month = oct,
  year = {2011},
  keywords = {Demosaicing},
  pages = {518-533}
}

@article{khashabiJointDemosaicingDenoising2014,
  title = {Joint {{Demosaicing}} and {{Denoising}} via {{Learned Nonparametric Random Fields}}},
  volume = {23},
  issn = {1057-7149},
  abstract = {We introduce a machine learning approach to demosaicing, the reconstruction of color images from incomplete color filter array samples. There are two challenges to overcome by a demosaicing method: 1) it needs to model and respect the statistics of natural images in order to reconstruct natural looking images and 2) it should be able to perform well in the presence of noise. To facilitate an objective assessment of current methods, we introduce a public ground truth data set of natural images suitable for research in image demosaicing and denoising. We then use this large data set to develop a machine learning approach to demosaicing. Our proposed method addresses both demosaicing challenges by learning a statistical model of images and noise from hundreds of natural images. The resulting model performs simultaneous demosaicing and denoising. We show that the machine learning approach has a number of benefits: 1) the model is trained to directly optimize a user-specified performance measure such as peak signal-to-noise ratio (PSNR) or structural similarity; 2) we can handle novel color filter array layouts by retraining the model on such layouts; and 3) it outperforms the previous state-of-the-art, in some setups by 0.7-dB PSNR, faithfully reconstructing edges, textures, and smooth areas. Our results demonstrate that in demosaicing and related imaging applications, discriminatively trained machine learning models have the potential for peak performance at comparatively low engineering effort.},
  number = {12},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2014.2359774},
  author = {Khashabi, D. and Nowozin, S. and Jancsary, J. and Fitzgibbon, A. W.},
  month = dec,
  year = {2014},
  keywords = {Demosaicing,image colour analysis,Interpolation,learning (artificial intelligence),image demosaicing,image reconstruction,color filter array,image denoising,Arrays,Cameras,color images reconstruction,demosaicing method,denoising,Image color analysis,Image edge detection,Image Processing; Computer-Assisted,imaging applications,learned nonparametric random fields,machine learning approach,machine learning models,natural images statistics,Noise,Noise reduction,peak signal-to-noise ratio,PSNR,Regression Analysis,regression tree fields,Signal-To-Noise Ratio,statistical analysis,statistical model,Statistics; Nonparametric},
  pages = {4968-4981},
  file = {/Users/markwang/DropBox (MIT)/zotero/Khashabi et al_2014_Joint Demosaicing and Denoising via Learned Nonparametric Random Fields.pdf;/Users/markwang/Zotero/storage/C549UW2J/6906294.html}
}

@article{chakrabartiRethinkingColorCameras2014,
  title = {Rethinking Color Cameras},
  abstract = {Digital color cameras make sub-sampled measurements of color at alternating pixel locations, and then ``demosaick'' these measurements to create full color images by up-sampling. This allows traditional cameras with restricted processing hardware to produce color images from a single shot, but it requires blocking a majority of the incident light and is prone to aliasing artifacts. In this paper, we introduce a computational approach to color photography, where the sampling pattern and reconstruction process are co-designed to enhance sharpness and photographic speed. The pattern is made predominantly panchromatic, thus avoiding excessive loss of light and aliasing of high spatial-frequency intensity variations. Color is sampled at a very sparse set of locations and then propagated throughout the image with guidance from the un-aliased luminance channel. Experimental results show that this approach often leads to significant reductions in noise and aliasing artifacts, especially in low-light conditions.},
  journal = {2014 IEEE International Conference on Computational Photography (ICCP)},
  doi = {10.1109/ICCPHOT.2014.6831801},
  author = {Chakrabarti, Ayan and Freeman, William T. and Zickler, Todd E.},
  year = {2014},
  keywords = {Demosaicing,Pixel,Color,Aliasing,Blocking (computing),Ray (optics),Sampling (signal processing),Sparse language,Sparse matrix},
  pages = {1-8},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chakrabarti et al_2014_Rethinking color cameras.pdf}
}

@article{heideFlexISPFlexibleCamera2014,
  title = {{{FlexISP}}: {{A Flexible Camera Image Processing Framework}}},
  volume = {33},
  issn = {0730-0301},
  shorttitle = {{{FlexISP}}},
  abstract = {Conventional pipelines for capturing, displaying, and storing images are usually defined as a series of cascaded modules, each responsible for addressing a particular problem. While this divide-and-conquer approach offers many benefits, it also introduces a cumulative error, as each step in the pipeline only considers the output of the previous step, not the original sensor data. We propose an end-to-end system that is aware of the camera and image model, enforces natural-image priors, while jointly accounting for common image processing steps like demosaicking, denoising, deconvolution, and so forth, all directly in a given output representation (e.g., YUV, DCT). Our system is flexible and we demonstrate it on regular Bayer images as well as images from custom sensors. In all cases, we achieve large improvements in image quality and signal reconstruction compared to state-of-the-art techniques. Finally, we show that our approach is capable of very efficiently handling high-resolution images, making even mobile implementations feasible.},
  number = {6},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/2661229.2661260},
  author = {Heide, Felix and Steinberger, Markus and Tsai, Yun-Ta and Rouf, Mushfiqur and Paj{\k{a}}k, Dawid and Reddy, Dikpal and Gallo, Orazio and Liu, Jing and Heidrich, Wolfgang and Egiazarian, Karen and Kautz, Jan and Pulli, Kari},
  month = nov,
  year = {2014},
  keywords = {image reconstruction,image processing},
  pages = {231:1--231:13},
  file = {/Users/markwang/DropBox (MIT)/zotero/Heide et al_2014_FlexISP - A Flexible Camera Image Processing Framework.pdf}
}

@article{gharbiDeepJointDemosaicking2016,
  title = {Deep {{Joint Demosaicking}} and {{Denoising}}},
  volume = {35},
  issn = {0730-0301},
  abstract = {Demosaicking and denoising are the key first stages of the digital imaging pipeline but they are also a severely ill-posed problem that infers three color values per pixel from a single noisy measurement. Earlier methods rely on hand-crafted filters or priors and still exhibit disturbing visual artifacts in hard cases such as moir{\'e} or thin edges. We introduce a new data-driven approach for these challenges: we train a deep neural network on a large corpus of images instead of using hand-tuned filters. While deep learning has shown great success, its naive application using existing training datasets does not give satisfactory results for our problem because these datasets lack hard cases. To create a better training set, we present metrics to identify difficult patches and techniques for mining community photographs for such patches. Our experiments show that this network and training procedure outperform state-of-the-art both on noisy and noise-free data. Furthermore, our algorithm is an order of magnitude faster than the previous best performing techniques.},
  number = {6},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/2980179.2982399},
  author = {Gharbi, Micha{\"e}l and Chaurasia, Gaurav and Paris, Sylvain and Durand, Fr{\'e}do},
  month = nov,
  year = {2016},
  keywords = {Demosaicing,denoising,convolutional neural networks,data driven methods,deep learning,demosaicking},
  pages = {191:1--191:12},
  file = {/Users/markwang/DropBox (MIT)/zotero/Gharbi et al_2016_Deep Joint Demosaicking and Denoising.pdf}
}

@article{klatzerLearningJointDemosaicing2016,
  title = {Learning Joint Demosaicing and Denoising Based on Sequential Energy Minimization},
  abstract = {Demosaicing is an important first step for color image acquisition. For practical reasons, demosaicing algorithms have to be both efficient and yield high quality results in the presence of noise. The demosaicing problem poses several challenges, e.g. zippering and false color artifacts as well as edge blur. In this work, we introduce a novel learning based method that can overcome these challenges. We formulate demosaicing as an image restoration problem and propose to learn efficient regularization inspired by a variational energy minimization framework that can be trained for different sensor layouts. Our algorithm performs joint demosaicing and denoising in close relation to the real physical mosaicing process on a camera sensor. This is achieved by learning a sequence of energy minimization problems composed of a set of RGB filters and corresponding activation functions. We evaluate our algorithm on the Microsoft Demosaicing data set in terms of peak signal to noise ratio (PSNR) and structured similarity index (SSIM). Our algorithm is highly efficient both in image quality and run time. We achieve an improvement of up to 2.6 dB over recent state-of-the-art algorithms.},
  journal = {2016 IEEE International Conference on Computational Photography (ICCP)},
  doi = {10.1109/ICCPHOT.2016.7492871},
  author = {Klatzer, Teresa and Hammernik, Kerstin and Kn{\"o}belreiter, Patrick and Pock, Thomas},
  year = {2016},
  keywords = {Algorithm,Color image,Demosaicing,Noise reduction,Activation function,Circuit restoration,Composite artifact colors,Convolution,Decibel,Display resolution,Edge enhancement,Energy minimization,Image quality,Image restoration,Image sensor,Matrix regularization,Microsoft Outlook for Mac,Peak signal-to-noise ratio,Run time (program lifecycle phase),Scene statistics,Structural similarity,Variational principle},
  pages = {1-11}
}

@article{kokkinosDeepImageDemosaicking2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.05215},
  primaryClass = {cs},
  title = {Deep {{Image Demosaicking}} Using a {{Cascade}} of {{Convolutional Residual Denoising Networks}}},
  abstract = {Demosaicking and denoising are among the most crucial steps of modern digital camera pipelines and their joint treatment is a highly ill-posed inverse problem where at-least two-thirds of the information are missing and the rest are corrupted by noise. This poses a great challenge in obtaining meaningful reconstructions and a special care for the efficient treatment of the problem is required. While there are several machine learning approaches that have been recently introduced to deal with joint image demosaicking-denoising, in this work we propose a novel deep learning architecture which is inspired by powerful classical image regularization methods and large-scale convex optimization techniques. Consequently, our derived network is more transparent and has a clear interpretation compared to alternative competitive deep learning approaches. Our extensive experiments demonstrate that our network outperforms any previous approaches on both noisy and noise-free data. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which also requires fewer trainable parameters than the current state-of-the-art deep network solution. Finally, we show that our network has the ability to generalize well even when it is trained on small datasets, while keeping the overall number of trainable parameters low.},
  journal = {arXiv:1803.05215 [cs]},
  author = {Kokkinos, Filippos and Lefkimmiatis, Stamatios},
  month = mar,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Kokkinos_Lefkimmiatis_2018_Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks.pdf;/Users/markwang/Zotero/storage/MKPEFIDA/1803.html}
}

@article{henzDeepJointDesign2018,
  title = {Deep {{Joint Design}} of {{Color Filter Arrays}} and {{Demosaicing}}},
  volume = {37},
  abstract = {We present a convolutional neural network architecture for performing joint design of color filter array (CFA) patterns and demosaicing. Our generic model allows the training of CFAs of arbitrary sizes, optimizing each color filter over the entire RGB color space. The patterns and algorithms produced by our method provide high-quality color reconstructions. We demonstrate the effectiveness of our approach by showing that its results achieve higher PSNR than the ones obtained with state-of-the-art techniques on all standard demosaicing datasets, both for noise-free and noisy scenarios. Our method can also be used to obtain demosaicing strategies for pre-defined CFAs, such as the Bayer pattern, for which our results also surpass even the demosaicing algorithms specifically designed for such a pattern.},
  journal = {Computer Graphics Forum},
  doi = {10.1111/cgf.13370},
  author = {Henz, Bernardo and S L Gastal, Eduardo and Oliveira, Manuel},
  month = may,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Henz et al_2018_Deep Joint Design of Color Filter Arrays and Demosaicing.pdf}
}

@article{zhouDeepResidualNetwork2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.06573},
  primaryClass = {cs},
  title = {Deep {{Residual Network}} for {{Joint Demosaicing}} and {{Super}}-{{Resolution}}},
  abstract = {In digital photography, two image restoration tasks have been studied extensively and resolved independently: demosaicing and super-resolution. Both these tasks are related to resolution limitations of the camera. Performing super-resolution on a demosaiced images simply exacerbates the artifacts introduced by demosaicing. In this paper, we show that such accumulation of errors can be easily averted by jointly performing demosaicing and super-resolution. To this end, we propose a deep residual network for learning an end-to-end mapping between Bayer images and high-resolution images. By training on high-quality samples, our deep residual demosaicing and super-resolution network is able to recover high-quality super-resolved images from low-resolution Bayer mosaics in a single step without producing the artifacts common to such processing when the two operations are done separately. We perform extensive experiments to show that our deep residual network achieves demosaiced and super-resolved images that are superior to the state-of-the-art both qualitatively and in terms of PSNR and SSIM metrics.},
  journal = {arXiv:1802.06573 [cs]},
  author = {Zhou, Ruofan and Achanta, Radhakrishna and S{\"u}sstrunk, Sabine},
  month = feb,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Zhou et al_2018_Deep Residual Network for Joint Demosaicing and Super-Resolution.pdf;/Users/markwang/Zotero/storage/4CDJ5T7A/1802.html}
}

@article{syuLearningDeepConvolutional2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.03769},
  primaryClass = {cs},
  title = {Learning {{Deep Convolutional Networks}} for {{Demosaicing}}},
  abstract = {This paper presents a comprehensive study of applying the convolutional neural network (CNN) to solving the demosaicing problem. The paper presents two CNN models that learn end-to-end mappings between the mosaic samples and the original image patches with full information. In the case the Bayer color filter array (CFA) is used, an evaluation with ten competitive methods on popular benchmarks confirms that the data-driven, automatically learned features by the CNN models are very effective. Experiments show that the proposed CNN models can perform equally well in both the sRGB space and the linear space. It is also demonstrated that the CNN model can perform joint denoising and demosaicing. The CNN model is very flexible and can be easily adopted for demosaicing with any CFA design. We train CNN models for demosaicing with three different CFAs and obtain better results than existing methods. With the great flexibility to be coupled with any CFA, we present the first data-driven joint optimization of the CFA design and the demosaicing method using CNN. Experiments show that the combination of the automatically discovered CFA pattern and the automatically devised demosaicing method significantly outperforms the current best demosaicing results. Visual comparisons confirm that the proposed methods reduce more visual artifacts than existing methods. Finally, we show that the CNN model is also effective for the more general demosaicing problem with spatially varying exposure and color and can be used for taking images of higher dynamic ranges with a single shot. The proposed models and the thorough experiments together demonstrate that CNN is an effective and versatile tool for solving the demosaicing problem.},
  journal = {arXiv:1802.03769 [cs]},
  author = {Syu, Nai-Sheng and Chen, Yu-Sheng and Chuang, Yung-Yu},
  month = feb,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Syu et al_2018_Learning Deep Convolutional Networks for Demosaicing.pdf;/Users/markwang/Zotero/storage/MAWHH7R3/1802.html}
}

@article{rudinNonlinearTotalVariation1992,
  title = {Nonlinear Total Variation Based Noise Removal Algorithms},
  volume = {60},
  issn = {0167-2789},
  abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t \textrightarrow {$\infty$} the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.},
  number = {1},
  journal = {Physica D: Nonlinear Phenomena},
  doi = {10.1016/0167-2789(92)90242-F},
  author = {Rudin, Leonid I. and Osher, Stanley and Fatemi, Emad},
  month = nov,
  year = {1992},
  keywords = {denoising},
  pages = {259-268},
  file = {/Users/markwang/DropBox (MIT)/zotero/Rudin et al_1992_Nonlinear total variation based noise removal algorithms.pdf;/Users/markwang/Zotero/storage/CVNSXIYP/016727899290242F.html}
}

@inproceedings{tomasiBilateralFilteringGray1998,
  title = {Bilateral Filtering for Gray and Color Images},
  abstract = {Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.},
  booktitle = {Sixth {{International Conference}} on {{Computer Vision}} ({{IEEE Cat}}. {{No}}.{{98CH36271}})},
  doi = {10.1109/ICCV.1998.710815},
  author = {Tomasi, C. and Manduchi, R.},
  month = jan,
  year = {1998},
  keywords = {Pixel,Color,denoising,image processing,bilateral filtering,color images,colour vision,Computer science,computer vision,edges preservation,Filtering,geometric closeness,gray images,Humans,Imaging phantoms,Low pass filters,perceptual metric,phantom colors,photometric similarity,Photometry,Shape measurement,Smoothing methods},
  pages = {839-846},
  file = {/Users/markwang/DropBox (MIT)/zotero/Tomasi_Manduchi_1998_Bilateral filtering for gray and color images.pdf;/Users/markwang/Zotero/storage/YICZC2ZI/710815.html}
}

@article{buadesNonlocalImageMovie2008,
  title = {Nonlocal {{Image}} and {{Movie Denoising}}},
  volume = {76},
  issn = {1573-1405},
  abstract = {Neighborhood filters are nonlocal image and movie filters which reduce the noise by averaging similar pixels. The first object of the paper is to present a unified theory of these filters and reliable criteria to compare them to other filter classes. A CCD noise model will be presented justifying the involvement of neighborhood filters. A classification of neighborhood filters will be proposed, including classical image and movie denoising methods and discussing further a recently introduced neighborhood filter, NL-means. In order to compare denoising methods three principles will be discussed. The first principle, ``method noise'', specifies that only noise must be removed from an image. A second principle will be introduced, ``noise to noise'', according to which a denoising method must transform a white noise into a white noise. Contrarily to ``method noise'', this principle, which characterizes artifact-free methods, eliminates any subjectivity and can be checked by mathematical arguments and Fourier analysis. ``Noise to noise'' will be proven to rule out most denoising methods, with the exception of neighborhood filters. This is why a third and new comparison principle, the ``statistical optimality'', is needed and will be introduced to compare the performance of all neighborhood filters. The three principles will be applied to compare ten different image and movie denoising methods. It will be first shown that only wavelet thresholding methods and NL-means give an acceptable method noise. Second, that neighborhood filters are the only ones to satisfy the ``noise to noise'' principle. Third, that among them NL-means is closest to statistical optimality. A particular attention will be paid to the application of the statistical optimality criterion for movie denoising methods. It will be pointed out that current movie denoising methods are motion compensated neighborhood filters. This amounts to say that they are neighborhood filters and that the ideal neighborhood of a pixel is its trajectory. Unfortunately the aperture problem makes it impossible to estimate ground true trajectories. It will be demonstrated that computing trajectories and restricting the neighborhood to them is harmful for denoising purposes and that space-time NL-means preserves more movie details.},
  language = {en},
  number = {2},
  journal = {International Journal of Computer Vision},
  doi = {10.1007/s11263-007-0052-1},
  author = {Buades, Antoni and Coll, Bartomeu and Morel, Jean-Michel},
  month = feb,
  year = {2008},
  keywords = {denoising,Image denoising,Motion estimation,Movie denoising},
  pages = {123-139},
  file = {/Users/markwang/DropBox (MIT)/zotero/Buades et al_2008_Nonlocal Image and Movie Denoising.pdf}
}

@article{afonsoFastImageRecovery2010,
  title = {Fast {{Image Recovery Using Variable Splitting}} and {{Constrained Optimization}}},
  volume = {19},
  issn = {1057-7149},
  abstract = {We propose a new fast algorithm for solving one of the standard formulations of image restoration and reconstruction which consists of an unconstrained optimization problem where the objective includes anl2data-fidelity term and a nonsmooth regularizer. This formulation allows both wavelet-based (with orthogonal or frame-based representations) regularization or total-variation regularization. Our approach is based on a variable splitting to obtain an equivalent constrained optimization formulation, which is then addressed with an augmented Lagrangian method. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence has been proved. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is faster than the current state of the art methods.},
  number = {9},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2010.2047910},
  author = {Afonso, M. V. and {Bioucas-Dias}, J. M. and Figueiredo, M. A. T.},
  month = sep,
  year = {2010},
  keywords = {Image reconstruction,Inverse problems,Pixel,image reconstruction,Convolution,Image restoration,alternating direction multiplier method,Augmented Lagrangian,augmented Lagrangian method,compressive sensing,Constraint optimization,convergence,Convergence,convex optimization,equivalent constrained optimization formulation,fast image recovery,Fourier transforms,Image coding,image restoration,inverse problems,l2data-fidelity term,Lagrangian functions,nonsmooth regularizer,optimisation,total variation,total-variation regularization,unconstrained optimization problem,variable splitting,wavelet transforms,wavelet-based regularization,wavelets},
  pages = {2345-2356},
  file = {/Users/markwang/DropBox (MIT)/zotero/Afonso et al_2010_Fast Image Recovery Using Variable Splitting and Constrained Optimization.pdf;/Users/markwang/Zotero/storage/3QS7U5L7/5445028.html}
}

@article{figueiredoRestorationPoissonianImages2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1001.2244},
  title = {Restoration of {{Poissonian Images Using Alternating Direction Optimization}}},
  volume = {19},
  issn = {1057-7149, 1941-0042},
  abstract = {Much research has been devoted to the problem of restoring Poissonian images, namely for medical and astronomical applications. However, the restoration of these images using state-of-the-art regularizers (such as those based on multiscale representations or total variation) is still an active research area, since the associated optimization problems are quite challenging. In this paper, we propose an approach to deconvolving Poissonian images, which is based on an alternating direction optimization method. The standard regularization (or maximum a posteriori) restoration criterion, which combines the Poisson log-likelihood with a (non-smooth) convex regularizer (log-prior), leads to hard optimization problems: the log-likelihood is non-quadratic and non-separable, the regularizer is non-smooth, and there is a non-negativity constraint. Using standard convex analysis tools, we present sufficient conditions for existence and uniqueness of solutions of these optimization problems, for several types of regularizers: total-variation, frame-based analysis, and frame-based synthesis. We attack these problems with an instance of the alternating direction method of multipliers (ADMM), which belongs to the family of augmented Lagrangian algorithms. We study sufficient conditions for convergence and show that these are satisfied, either under total-variation or frame-based (analysis and synthesis) regularization. The resulting algorithms are shown to outperform alternative state-of-the-art methods, both in terms of speed and restoration accuracy.},
  number = {12},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2010.2053941},
  author = {Figueiredo, M{\'a}rio A. T. and {Bioucas-Dias}, Jos{\'e} M.},
  month = dec,
  year = {2010},
  keywords = {admm,Mathematics - Optimization and Control,denoising,94A08; 47N10,Mathematics - Numerical Analysis},
  pages = {3133-3145},
  file = {/Users/markwang/DropBox (MIT)/zotero/Figueiredo_Bioucas-Dias_2010_Restoration of Poissonian Images Using Alternating Direction Optimization.pdf;/Users/markwang/Zotero/storage/T7UBSIJC/1001.html}
}

@article{buadesReviewImageDenoising2005,
  title = {A {{Review}} of {{Image Denoising Algorithms}}, with a {{New One}}},
  volume = {4},
  issn = {1540-3459},
  abstract = {The search for efficient image denoising methods is still a valid challenge at the crossing of functional analysis and statistics. In spite of the sophistication of the recently proposed methods, most algorithms have not yet attained a desirable level of applicability. All show an outstanding performance when the image model corresponds to the algorithm assumptions but fail in general and create artifacts or remove image fine structures. The main focus of this paper is, first, to define a general mathematical and experimental methodology to compare and classify classical image denoising algorithms and, second, to propose a nonlocal means (NL-means) algorithm addressing the preservation of structure in a digital image. The mathematical analysis is based on the analysis of the "method noise," defined as the difference between a digital image and its denoised version. The NL-means algorithm is proven to be asymptotically optimal under a generic statistical image model. The denoising performance of all considered methods are compared in four ways; mathematical: asymptotic order of magnitude of the method noise under regularity assumptions; perceptual-mathematical: the algorithms artifacts and their explanation as a violation of the image model; quantitative experimental: by tables of L2  distances of the denoised version to the original image. The most powerful evaluation method seems, however, to be the visualization of the method noise on natural images. The more this method noise looks like a real white noise, the better the method.},
  number = {2},
  journal = {Multiscale Modeling \& Simulation},
  doi = {10.1137/040616024},
  author = {Buades, A. and Coll, B. and Morel, J.},
  month = jan,
  year = {2005},
  keywords = {review},
  pages = {490-530},
  file = {/Users/markwang/DropBox (MIT)/zotero/Buades et al_2005_A Review of Image Denoising Algorithms, with a New One.pdf;/Users/markwang/Zotero/storage/QZZSJLZE/040616024.html}
}

@inproceedings{venkatakrishnanPlugandPlayPriorsModel2013,
  title = {Plug-and-{{Play}} Priors for Model Based Reconstruction},
  abstract = {Model-based reconstruction is a powerful framework for solving a variety of inverse problems in imaging. In recent years, enormous progress has been made in the problem of denoising, a special case of an inverse problem where the forward model is an identity operator. Similarly, great progress has been made in improving model-based inversion when the forward model corresponds to complex physical measurements in applications such as X-ray CT, electron-microscopy, MRI, and ultrasound, to name just a few. However, combining state-of-the-art denoising algorithms (i.e., prior models) with state-of-the-art inversion methods (i.e., forward models) has been a challenge for many reasons. In this paper, we propose a flexible framework that allows state-of-the-art forward models of imaging systems to be matched with state-of-the-art priors or denoising models. This framework, which we term as Plug-and-Play priors, has the advantage that it dramatically simplifies software integration, and moreover, it allows state-of-the-art denoising methods that have no known formulation as an optimization problem to be used. We demonstrate with some simple examples how Plug-and-Play priors can be used to mix and match a wide variety of existing denoising models with a tomographic forward model, thus greatly expanding the range of possible problem solutions.},
  booktitle = {2013 {{IEEE Global Conference}} on {{Signal}} and {{Information Processing}}},
  doi = {10.1109/GlobalSIP.2013.6737048},
  author = {Venkatakrishnan, S. V. and Bouman, C. A. and Wohlberg, B.},
  month = dec,
  year = {2013},
  keywords = {Image reconstruction,Inverse problems,optimization problem,image reconstruction,image denoising,Noise reduction,inverse problems,optimisation,Computational modeling,denoising models,imaging system forward models,model based reconstruction,Optimization,Phantoms,plug-and-play priors,software integration,tomographic forward model,Tomography},
  pages = {945-948},
  file = {/Users/markwang/DropBox (MIT)/zotero/Venkatakrishnan et al_2013_Plug-and-Play priors for model based reconstruction.pdf;/Users/markwang/Zotero/storage/5442BBKX/6737048.html}
}

@article{liuProgressiveImageDenoising2014,
  title = {Progressive {{Image Denoising Through Hybrid Graph Laplacian Regularization}}: {{A Unified Framework}}},
  volume = {23},
  issn = {1057-7149},
  shorttitle = {Progressive {{Image Denoising Through Hybrid Graph Laplacian Regularization}}},
  abstract = {Recovering images from corrupted observations is necessary for many real-world applications. In this paper, we propose a unified framework to perform progressive image recovery based on hybrid graph Laplacian regularized regression. We first construct a multiscale representation of the target image by Laplacian pyramid, then progressively recover the degraded image in the scale space from coarse to fine so that the sharp edges and texture can be eventually recovered. On one hand, within each scale, a graph Laplacian regularization model represented by implicit kernel is learned, which simultaneously minimizes the least square error on the measured samples and preserves the geometrical structure of the image data space. In this procedure, the intrinsic manifold structure is explicitly considered using both measured and unmeasured samples, and the nonlocal self-similarity property is utilized as a fruitful resource for abstracting a priori knowledge of the images. On the other hand, between two successive scales, the proposed model is extended to a projected high-dimensional feature space through explicit kernel mapping to describe the interscale correlation, in which the local structure regularity is learned and propagated from coarser to finer scales. In this way, the proposed algorithm gradually recovers more and more image details and edges, which could not been recovered in previous scale. We test our algorithm on one typical image recovery task: impulse noise removal. Experimental results on benchmark test images demonstrate that the proposed method achieves better performance than state-of-the-art algorithms.},
  number = {4},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2014.2303638},
  author = {Liu, X. and Zhai, D. and Zhao, D. and Zhai, G. and Gao, W.},
  month = apr,
  year = {2014},
  keywords = {image denoising,Image edge detection,Noise,Image denoising,Correlation,corrupted observations,Data models,explicit kernel mapping,geometrical structure,graph Laplacian,graph theory,hybrid graph,image data space,image representation,implicit kernel,impulse noise,impulse noise removal,intrinsic manifold structure,Kernel,kernel theory,Laplace equations,Laplace transforms,Laplacian pyramid,Laplacian regularized regression,least square error,least squares approximations,local smoothness,multiscale image representation,Noise measurement,non-local self-similarity,nonlocal self-similarity property,progressive image denoising,progressive image recovery,projected high-dimensional feature space,real-world applications,regression analysis,scale space,sharp edges,unified framework},
  pages = {1491-1503},
  file = {/Users/markwang/DropBox (MIT)/zotero/Liu et al_2014_Progressive Image Denoising Through Hybrid Graph Laplacian Regularization - A Unified Framework.pdf;/Users/markwang/Zotero/storage/BEH6IXHA/6728689.html}
}

@article{chanAlgorithmInducedPriorImage2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.00715},
  title = {Algorithm-{{Induced Prior}} for {{Image Restoration}}},
  volume = {abs/1602.00715},
  abstract = {This paper studies a type of image priors that are constructed implicitly through the alternating direction method of multiplier (ADMM) algorithm, called the algorithm-induced prior. Different from classical image priors which are defined before running the reconstruction algorithm, algorithm-induced priors are defined by the denoising procedure used to replace one of the two modules in the ADMM algorithm. Since such prior is not explicitly defined, analyzing the performance has been difficult in the past. 
Focusing on the class of symmetric smoothing filters, this paper presents an explicit expression of the prior induced by the ADMM algorithm. The new prior is reminiscent to the conventional graph Laplacian but with stronger reconstruction performance. It can also be shown that the overall reconstruction has an efficient closed-form implementation if the associated symmetric smoothing filter is low rank. The results are validated with experiments on image inpainting.},
  journal = {ArXiv},
  author = {Chan, Stanley H.},
  year = {2016},
  keywords = {Algorithm,Experiment,Noise reduction,Image restoration,Inpainting,Laplacian matrix,Optimization problem,Smoothing},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chan_2016_Algorithm-Induced Prior for Image Restoration.pdf}
}

@incollection{yangDeepADMMNetCompressive2016,
  title = {Deep {{ADMM}}-{{Net}} for {{Compressive Sensing MRI}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  author = {{yang}, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  pages = {10--18},
  file = {/Users/markwang/DropBox (MIT)/zotero/yang et al_2016_Deep ADMM-Net for Compressive Sensing MRI.pdf;/Users/markwang/Zotero/storage/2KKE3C4G/6406-deep-admm-net-for-compressive-sensing-mri.html}
}

@article{chanPlugandPlayADMMImage2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.01710},
  primaryClass = {cs},
  title = {Plug-and-{{Play ADMM}} for {{Image Restoration}}: {{Fixed Point Convergence}} and {{Applications}}},
  shorttitle = {Plug-and-{{Play ADMM}} for {{Image Restoration}}},
  abstract = {Alternating direction method of multiplier (ADMM) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the ADMM algorithm is its modular structure which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the ADMM algorithm. Because of the plug-in nature, this type of ADMM algorithms is coined the name "Plug-and-Play ADMM". Plug-and-Play ADMM has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play ADMM uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play ADMM algorithm with provable fixed point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play ADMM converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on super-resolution and single-photon imaging. We compare Plug-and-Play ADMM with state-of-the-art algorithms in each problem type, and demonstrate promising experimental results of the algorithm.},
  journal = {arXiv:1605.01710 [cs]},
  author = {Chan, Stanley H. and Wang, Xiran and Elgendy, Omar A.},
  month = may,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chan et al_2016_Plug-and-Play ADMM for Image Restoration - Fixed Point Convergence and Applications.pdf;/Users/markwang/Zotero/storage/XH9CR7Y7/1605.html}
}

@article{heideProxImaLEfficientImage2016,
  title = {{{ProxImaL}}: Efficient Image Optimization Using Proximal Algorithms},
  volume = {35},
  issn = {07300301},
  shorttitle = {{{ProxImaL}}},
  abstract = {Computational photography systems are becoming increasingly diverse, while computational resources\textemdash{}for example on mobile platforms\textemdash{}are rapidly increasing. As diverse as these camera systems may be, slightly different variants of the underlying image processing tasks, such as demosaicking, deconvolution, denoising, inpainting, image fusion, and alignment, are shared between all of these systems. Formal optimization methods have recently been demonstrated to achieve state-of-the-art quality for many of these applications. Unfortunately, different combinations of natural image priors and optimization algorithms may be optimal for different problems, and implementing and testing each combination is currently a time-consuming and error-prone process. ProxImaL is a domainspecific language and compiler for image optimization problems that makes it easy to experiment with different problem formulations and algorithm choices. The language uses proximal operators as the fundamental building blocks of a variety of linear and nonlinear image formation models and cost functions, advanced image priors, and noise models. The compiler intelligently chooses the best way to translate a problem formulation and choice of optimization algorithm into an efficient solver implementation. In applications to the image processing pipeline, deconvolution in the presence of Poisson-distributed shot noise, and burst denoising, we show that a few lines of ProxImaL code can generate highly efficient solvers that achieve state-of-the-art results. We also show applications to the nonlinear and nonconvex problem of phase retrieval.},
  language = {en},
  number = {4},
  journal = {ACM Transactions on Graphics},
  doi = {10.1145/2897824.2925875},
  author = {Heide, Felix and Diamond, Steven and Nie{\ss}ner, Matthias and {Ragan-Kelley}, Jonathan and Heidrich, Wolfgang and Wetzstein, Gordon},
  month = jul,
  year = {2016},
  pages = {1-15},
  file = {/Users/markwang/DropBox (MIT)/zotero/Heide et al_2016_ProxImaL - efficient image optimization using proximal algorithms.pdf}
}

@article{zhangLearningDeepCNN2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03264},
  primaryClass = {cs},
  title = {Learning {{Deep CNN Denoiser Prior}} for {{Image Restoration}}},
  abstract = {Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.},
  journal = {arXiv:1704.03264 [cs]},
  author = {Zhang, Kai and Zuo, Wangmeng and Gu, Shuhang and Zhang, Lei},
  month = apr,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Zhang et al_2017_Learning Deep CNN Denoiser Prior for Image Restoration.pdf;/Users/markwang/Zotero/storage/26UVPKRU/1704.html}
}

@article{meinhardtLearningProximalOperators2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03488},
  primaryClass = {cs},
  title = {Learning {{Proximal Operators}}: {{Using Denoising Networks}} for {{Regularizing Inverse Imaging Problems}}},
  shorttitle = {Learning {{Proximal Operators}}},
  abstract = {While variational methods have been among the most powerful tools for solving linear inverse problems in imaging, deep (convolutional) neural networks have recently taken the lead in many challenging benchmarks. A remaining drawback of deep learning approaches is their requirement for an expensive retraining whenever the specific problem, the noise level, noise type, or desired measure of fidelity changes. On the contrary, variational methods have a plug-and-play nature as they usually consist of separate data fidelity and regularization terms. In this paper we study the possibility of replacing the proximal operator of the regularization used in many convex energy minimization algorithms by a denoising neural network. The latter therefore serves as an implicit natural image prior, while the data term can still be chosen independently. Using a fixed denoising neural network in exemplary problems of image deconvolution with different blur kernels and image demosaicking, we obtain state-of-the-art reconstruction results. These indicate the high generalizability of our approach and a reduction of the need for problem-specific training. Additionally, we discuss novel results on the analysis of possible optimization algorithms to incorporate the network into, as well as the choices of algorithm parameters and their relation to the noise level the neural network is trained on.},
  journal = {arXiv:1704.03488 [cs]},
  author = {Meinhardt, Tim and Moeller, Michael and Hazirbas, Caner and Cremers, Daniel},
  month = apr,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Meinhardt et al_2017_Learning Proximal Operators - Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf;/Users/markwang/Zotero/storage/6XFSE8ET/1704.html}
}

@article{romanoLittleEngineThat2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.02862},
  primaryClass = {cs},
  title = {The {{Little Engine}} That {{Could}}: {{Regularization}} by {{Denoising}} ({{RED}})},
  shorttitle = {The {{Little Engine}} That {{Could}}},
  abstract = {Removal of noise from an image is an extensively studied problem in image processing. Indeed, the recent advent of sophisticated and highly effective denoising algorithms lead some to believe that existing methods are touching the ceiling in terms of noise removal performance. Can we leverage this impressive achievement to treat other tasks in image processing? Recent work has answered this question positively, in the form of the Plug-and-Play Prior (\$P\^3\$) method, showing that any inverse problem can be handled by sequentially applying image denoising steps. This relies heavily on the ADMM optimization technique in order to obtain this chained denoising interpretation. Is this the only way in which tasks in image processing can exploit the image denoising engine? In this paper we provide an alternative, more powerful and more flexible framework for achieving the same goal. As opposed to the \$P\^3\$ method, we offer Regularization by Denoising (RED): using the denoising engine in defining the regularization of the inverse problem. We propose an explicit image-adaptive Laplacian-based regularization functional, making the overall objective functional clearer and better defined. With a complete flexibility to choose the iterative optimization procedure for minimizing the above functional, RED is capable of incorporating any image denoising algorithm, treat general inverse problems very effectively, and is guaranteed to converge to the globally optimal result. We test this approach and demonstrate state-of-the-art results in the image deblurring and super-resolution problems.},
  journal = {arXiv:1611.02862 [cs]},
  author = {Romano, Yaniv and Elad, Michael and Milanfar, Peyman},
  month = nov,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Mathematics - Numerical Analysis},
  file = {/Users/markwang/DropBox (MIT)/zotero/Romano et al_2016_The Little Engine that Could - Regularization by Denoising (RED).pdf}
}

@incollection{yangProximalDehazeNetPrior2018,
  address = {{Cham}},
  title = {Proximal {{Dehaze}}-{{Net}}: {{A Prior Learning}}-{{Based Deep Network}} for {{Single Image Dehazing}}},
  volume = {11211},
  isbn = {978-3-030-01233-5 978-3-030-01234-2},
  shorttitle = {Proximal {{Dehaze}}-{{Net}}},
  abstract = {Photos taken in hazy weather are usually covered with white masks and often lose important details. In this paper, we propose a novel deep learning approach for single image dehazing by learning dark channel and transmission priors. First, we build an energy model for dehazing using dark channel and transmission priors and design an iterative optimization algorithm using proximal operators for these two priors. Second, we unfold the iterative algorithm to be a deep network, dubbed as proximal dehaze-net, by learning the proximal operators using convolutional neural networks. Our network combines the advantages of traditional prior-based dehazing methods and deep learning methods by incorporating haze-related prior learning into deep network. Experiments show that our method achieves state-of-the-art performance for single image dehazing.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  publisher = {{Springer International Publishing}},
  author = {Yang, Dong and Sun, Jian},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  pages = {729-746},
  file = {/Users/markwang/DropBox (MIT)/zotero/Yang_Sun_2018_Proximal Dehaze-Net - A Prior Learning-Based Deep Network for Single Image Dehazing.pdf},
  doi = {10.1007/978-3-030-01234-2_43}
}

@article{reehorstRegularizationDenoisingClarifications2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.02296},
  primaryClass = {cs},
  title = {Regularization by {{Denoising}}: {{Clarifications}} and {{New Interpretations}}},
  shorttitle = {Regularization by {{Denoising}}},
  abstract = {Regularization by Denoising (RED), as recently proposed by Romano, Elad, and Milanfar, is powerful image-recovery framework that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function. Experimental evidence suggests that the RED algorithms are state-of-the-art. We claim, however, that explicit regularization does not explain the RED algorithms. In particular, we show that many of the expressions in the paper by Romano et al. hold only when the denoiser has a symmetric Jacobian, and we demonstrate that such symmetry does not occur with practical denoisers such as non-local means, BM3D, TNRD, and DnCNN. To explain the RED algorithms, we propose a new framework called Score-Matching by Denoising (SMD), which aims to match a "score" (i.e., the gradient of a log-prior). We then show tight connections between SMD, kernel density estimation, and constrained minimum mean-squared error denoising. Furthermore, we interpret the RED algorithms from Romano et al. and propose new algorithms with acceleration and convergence guarantees. Finally, we show that the RED algorithms seek a consensus equilibrium solution, which facilitates a comparison to plug-and-play ADMM.},
  journal = {arXiv:1806.02296 [cs]},
  author = {Reehorst, Edward T. and Schniter, Philip},
  month = jun,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Reehorst_Schniter_2018_Regularization by Denoising - Clarifications and New Interpretations.pdf;/Users/markwang/Zotero/storage/JGU54Q6A/1806.html}
}

@article{sunBlockCoordinateRegularization2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.05113},
  primaryClass = {cs, eess},
  title = {Block {{Coordinate Regularization}} by {{Denoising}}},
  abstract = {We consider the problem of estimating a vector from its noisy measurements using a prior specified only through a denoising function. Recent work on plug-and-play priors (PnP) and regularization-by-denoising (RED) has shown the state-of-the-art performance of estimators under such priors in a range of imaging tasks. In this work, we develop a new block coordinate RED algorithm that decomposes a large-scale estimation problem into a sequence of updates over a small subset of the unknown variables. We theoretically analyze the convergence of the algorithm and discuss its relationship to the traditional proximal optimization. Our analysis complements and extends recent theoretical results for RED-based estimation methods. We numerically validate our method using several denoiser priors, including those based on convolutional neural network (CNN) denoisers.},
  journal = {arXiv:1905.05113 [cs, eess]},
  author = {Sun, Yu and Liu, Jiaming and Kamilov, Ulugbek S.},
  month = may,
  year = {2019},
  file = {/Users/markwang/DropBox (MIT)/zotero/Sun et al_2019_Block Coordinate Regularization by Denoising.pdf;/Users/markwang/Zotero/storage/N5Z3LHLF/1905.html}
}

@article{mataevDeepREDDeepImage2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1903.10176},
  primaryClass = {cs, eess},
  title = {{{DeepRED}}: {{Deep Image Prior Powered}} by {{RED}}},
  shorttitle = {{{DeepRED}}},
  abstract = {Inverse problems in imaging are extensively studied, with a variety of strategies, tools, and theory that have been accumulated over the years. Recently, this field has been immensely influenced by the emergence of deep-learning techniques. One such contribution, which is the focus of this paper, is the Deep Image Prior (DIP) work by Ulyanov, Vedaldi, and Lempitsky (2018). DIP offers a new approach towards the regularization of inverse problems, obtained by forcing the recovered image to be synthesized from a given deep architecture. While DIP has been shown to be effective, its results fall short when compared to state-of-the-art alternatives. In this work, we aim to boost DIP by adding an explicit prior, which enriches the overall regularization effect in order to lead to better-recovered images. More specifically, we propose to bring-in the concept of Regularization by Denoising (RED), which leverages existing denoisers for regularizing inverse problems. Our work shows how the two (DeepRED) can be merged to a highly effective recovery process while avoiding the need to differentiate the chosen denoiser, and leading to very effective results, demonstrated for several tested inverse problems.},
  journal = {arXiv:1903.10176 [cs, eess]},
  author = {Mataev, Gary and Elad, Michael and Milanfar, Peyman},
  month = mar,
  year = {2019},
  file = {/Users/markwang/DropBox (MIT)/zotero/Mataev et al_2019_DeepRED - Deep Image Prior Powered by RED.pdf;/Users/markwang/Zotero/storage/YRHRXUPH/1903.html}
}

@article{diamondUnrolledOptimizationDeep2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.08041},
  primaryClass = {cs},
  title = {Unrolled {{Optimization}} with {{Deep Priors}}},
  abstract = {A broad class of problems at the core of computational imaging, sensing, and low-level computer vision reduces to the inverse problem of extracting latent images that follow a prior distribution, from measurements taken under a known physical image formation model. Traditionally, hand-crafted priors along with iterative optimization methods have been used to solve such problems. In this paper we present unrolled optimization with deep priors, a principled framework for infusing knowledge of the image formation into deep networks that solve inverse problems in imaging, inspired by classical iterative methods. We show that instances of the framework outperform the state-of-the-art by a substantial margin for a wide variety of imaging problems, such as denoising, deblurring, and compressed sensing magnetic resonance imaging (MRI). Moreover, we conduct experiments that explain how the framework is best used and why it outperforms previous methods.},
  journal = {arXiv:1705.08041 [cs]},
  author = {Diamond, Steven and Sitzmann, Vincent and Heide, Felix and Wetzstein, Gordon},
  month = may,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Diamond et al_2017_Unrolled Optimization with Deep Priors.pdf;/Users/markwang/Zotero/storage/NN68YC3F/1705.html}
}

@article{salviPatternCodificationStrategies2004,
  series = {Agent {{Based Computer Vision}}},
  title = {Pattern Codification Strategies in Structured Light Systems},
  volume = {37},
  issn = {0031-3203},
  abstract = {Coded structured light is considered one of the most reliable techniques for recovering the surface of objects. This technique is based on projecting a light pattern and viewing the illuminated scene from one or more points of view. Since the pattern is coded, correspondences between image points and points of the projected pattern can be easily found. The decoded points can be triangulated and 3D information is obtained. We present an overview of the existing techniques, as well as a new and definitive classification of patterns for structured light sensors. We have implemented a set of representative techniques in this field and present some comparative results. The advantages and constraints of the different patterns are also discussed.},
  number = {4},
  journal = {Pattern Recognition},
  doi = {10.1016/j.patcog.2003.10.002},
  author = {Salvi, Joaquim and Pag{\`e}s, Jordi and Batlle, Joan},
  month = apr,
  year = {2004},
  keywords = {3D measuring devices,Active stereo,Coded patterns,Computer vision,Structured light},
  pages = {827-849},
  file = {/Users/markwang/DropBox (MIT)/zotero/Salvi et al_2004_Pattern codification strategies in structured light systems.pdf;/Users/markwang/Zotero/storage/MWLFIADJ/S0031320303003303.html}
}

@inproceedings{guptaMicroPhaseShifting2012,
  address = {{Providence, RI}},
  title = {Micro {{Phase Shifting}}},
  isbn = {978-1-4673-1228-8 978-1-4673-1226-4 978-1-4673-1227-1},
  abstract = {We consider the problem of shape recovery for real world scenes, where a variety of global illumination (interreflections, subsurface scattering, etc.) and illumination defocus effects are present. These effects introduce systematic and often significant errors in the recovered shape. We introduce a structured light technique called Micro Phase Shifting, which overcomes these problems. The key idea is to project sinusoidal patterns with frequencies limited to a narrow, highfrequency band. These patterns produce a set of images over which global illumination and defocus effects remain constant for each point in the scene. This enables high quality reconstructions of scenes which have traditionally been considered hard, using only a small number of images. We also derive theoretical lower bounds on the number of input images needed for phase shifting and show that Micro PS achieves the bound.},
  language = {en},
  booktitle = {2012 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  publisher = {{IEEE}},
  doi = {10.1109/CVPR.2012.6247753},
  author = {Gupta, M. and Nayar, S. K.},
  month = jun,
  year = {2012},
  pages = {813-820},
  file = {/Users/markwang/DropBox (MIT)/zotero/Gupta_Nayar_2012_Micro Phase Shifting.pdf}
}

@inproceedings{bougleuxDiscreteRegularizationWeighted2007,
  address = {{Ischia, Italy}},
  series = {{{LNCS}}},
  title = {Discrete {{Regularization}} on {{Weighted Graphs}} for {{Image}} and {{Mesh Filtering}}},
  volume = {4485},
  abstract = {We propose a discrete regularization framework on weighted graphs of arbitrary topology, which unifies image and mesh filtering. The approach considers the problem as a variational one, which consists in minimizing a weighted sum of two energy terms: a regularization one that uses the discrete p-Laplace operator, and an approximation one. This formulation leads to a family of simple nonlinear filters, parameterized by the degree p of smoothness and by the graph weight function. Some of these filters provide a graph-based version of well-known filters used in image and mesh processing, such as the bilateral filter, the TV digital filter or the nonlocal mean filter.},
  booktitle = {1st {{International Conference}} on {{Scale Space}} and {{Variational Methods}} in {{Computer Vision}} ({{SSVM}} 2007)},
  publisher = {{Springer}},
  doi = {10.1007/978-3-540-72823-8_12},
  author = {Bougleux, S{\'e}bastien and Elmoataz, Abderrahim and Melkemi, Mahmoud},
  month = may,
  year = {2007},
  pages = {128-139},
  file = {/Users/markwang/DropBox (MIT)/zotero/Bougleux et al_2007_Discrete Regularization on Weighted Graphs for Image and Mesh Filtering.pdf}
}

@article{elmoatazNonlocalDiscreteRegularization2008,
  title = {Nonlocal {{Discrete Regularization}} on {{Weighted Graphs}}: {{A Framework}} for {{Image}} and {{Manifold Processing}}},
  volume = {17},
  issn = {1057-7149, 1941-0042},
  shorttitle = {Nonlocal {{Discrete Regularization}} on {{Weighted Graphs}}},
  abstract = {We introduce a nonlocal discrete regularization framework on weighted graphs of the arbitrary topologies for image and manifold processing. The approach considers the problem as a variational one, which consists in minimizing a weighted sum of two energy terms: a regularization one that uses a discrete weighted p-Dirichlet energy, and an approximation one. This is the discrete analogue of recent continuous Euclidean nonlocal regularization functionals. The proposed formulation leads to a family of simple and fast nonlinear processing methods based on the weighted p-Laplace operator, parameterized by the degree p of regularity, the graph structure and the graph weight function. These discrete processing methods provide a graph-based version of recently proposed semi-local or nonlocal processing methods used in image and mesh processing, such as the bilateral filter, the TV digital filter or the nonlocal means filter. It works with equal ease on regular 2D-3D images, manifolds or any data. We illustrate the abilities of the approach by applying it to various types of images, meshes, manifolds and data represented as graphs.},
  language = {en},
  number = {7},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2008.924284},
  author = {Elmoataz, A. and Lezoray, O. and Bougleux, S.},
  month = jul,
  year = {2008},
  pages = {1047-1060},
  file = {/Users/markwang/DropBox (MIT)/zotero/Elmoataz et al_2008_Nonlocal Discrete Regularization on Weighted Graphs - A Framework for Image and Manifold Processing.pdf}
}

@article{reuterDiscreteLaplaceBeltrami2009,
  series = {{{IEEE International Conference}} on {{Shape Modelling}} and {{Applications}} 2009},
  title = {Discrete {{Laplace}}\textendash{{Beltrami}} Operators for Shape Analysis and Segmentation},
  volume = {33},
  issn = {0097-8493},
  abstract = {Shape analysis plays a pivotal role in a large number of applications, ranging from traditional geometry processing to more recent 3D content management. In this scenario, spectral methods are extremely promising as they provide a natural library of tools for shape analysis, intrinsically defined by the shape itself. In particular, the eigenfunctions of the Laplace\textendash{}Beltrami operator yield a set of real-valued functions that provide interesting insights in the structure and morphology of the shape. In this paper, we first analyze different discretizations of the Laplace\textendash{}Beltrami operator (geometric Laplacians, linear and cubic FEM operators) in terms of the correctness of their eigenfunctions with respect to the continuous case. We then present the family of segmentations induced by the nodal sets of the eigenfunctions, discussing its meaningfulness for shape understanding.},
  number = {3},
  journal = {Computers \& Graphics},
  doi = {10.1016/j.cag.2009.03.005},
  author = {Reuter, Martin and Biasotti, Silvia and Giorgi, Daniela and Patan{\`e}, Giuseppe and Spagnuolo, Michela},
  month = jun,
  year = {2009},
  keywords = {Eigenfunctions,Laplaceâ€“Beltrami operator,Nodal domains,Nodal sets,Shape analysis,Shape segmentation},
  pages = {381-390},
  file = {/Users/markwang/DropBox (MIT)/zotero/Reuter et al_2009_Discrete Laplaceâ€“Beltrami operators for shape analysis and segmentation.pdf;/Users/markwang/Zotero/storage/WF3IFBDE/S0097849309000272.html}
}

@inproceedings{wardetzkyDiscreteLaplaceOperators2008,
  address = {{Singapore}},
  title = {Discrete {{Laplace}} Operators: No Free Lunch},
  shorttitle = {Discrete {{Laplace}} Operators},
  abstract = {Discrete Laplace operators are ubiquitous in applications spanning geometric modeling to simulation. For robustness and efficiency, many applications require discrete operators that retain key structural properties inherent to the continuous setting. Building on the smooth setting, we present a set of natural properties for discrete Laplace operators for triangular surface meshes. We prove an important theoretical limitation: discrete Laplacians cannot satisfy all natural properties; retroactively, this explains the diversity of existing discrete Laplace operators. Finally, we present a family of operators that includes and extends well-known and widely-used operators.},
  language = {en},
  booktitle = {{{ACM SIGGRAPH ASIA}} 2008 Courses on - {{SIGGRAPH Asia}} '08},
  publisher = {{ACM Press}},
  doi = {10.1145/1508044.1508063},
  author = {Wardetzky, Max and Mathur, Saurabh and K{\"a}lberer, Felix and Grinspun, Eitan},
  year = {2008},
  pages = {1-5},
  file = {/Users/markwang/DropBox (MIT)/zotero/Wardetzky et al_2008_Discrete Laplace operators - no free lunch.pdf}
}

@article{sitzmannEndtoendOptimizationOptics2018,
  title = {End-to-End {{Optimization}} of {{Optics}} and {{Image Processing}} for {{Achromatic Extended Depth}} of {{Field}} and {{Super}}-Resolution {{Imaging}}},
  volume = {37},
  issn = {0730-0301},
  abstract = {In typical cameras the optical system is designed first; once it is fixed, the parameters in the image processing algorithm are tuned to get good image reproduction. In contrast to this sequential design approach, we consider joint optimization of an optical system (for example, the physical shape of the lens) together with the parameters of the reconstruction algorithm. We build a fully-differentiable simulation model that maps the true source image to the reconstructed one. The model includes diffractive light propagation, depth and wavelength-dependent effects, noise and nonlinearities, and the image post-processing. We jointly optimize the optical parameters and the image processing algorithm parameters so as to minimize the deviation between the true and reconstructed image, over a large set of images. We implement our joint optimization method using autodifferentiation to efficiently compute parameter gradients in a stochastic optimization algorithm. We demonstrate the efficacy of this approach by applying it to achromatic extended depth of field and snapshot super-resolution imaging.},
  number = {4},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/3197517.3201333},
  author = {Sitzmann, Vincent and Diamond, Steven and Peng, Yifan and Dun, Xiong and Boyd, Stephen and Heidrich, Wolfgang and Heide, Felix and Wetzstein, Gordon},
  month = jul,
  year = {2018},
  keywords = {computational,optics},
  pages = {114:1--114:13},
  file = {/Users/markwang/DropBox (MIT)/zotero/Sitzmann et al_2018_End-to-end Optimization of Optics and Image Processing for Achromatic Extended Depth of Field and Super-resolution Imaging.pdf}
}

@inproceedings{rothFieldsExpertsFramework2005,
  address = {{San Diego, CA, USA}},
  title = {Fields of {{Experts}}: {{A Framework}} for {{Learning Image Priors}}},
  volume = {2},
  isbn = {978-0-7695-2372-9},
  shorttitle = {Fields of {{Experts}}},
  abstract = {We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov Random Field (MRF) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we obtain results that compete with and even outperform specialized techniques.},
  language = {en},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  publisher = {{IEEE}},
  doi = {10.1109/CVPR.2005.160},
  author = {Roth, S. and Black, M.J.},
  year = {2005},
  pages = {860-867},
  file = {/Users/markwang/DropBox (MIT)/zotero/Roth_Black_2005_Fields of Experts - A Framework for Learning Image Priors.pdf}
}

@article{gregorLearningFastApproximations,
  title = {Learning {{Fast Approximations}} of {{Sparse Coding}}},
  abstract = {In Sparse Coding (SC), input vectors are reconstructed using a sparse linear combination of basis vectors. SC has become a popular method for extracting features from data. For a given input, SC minimizes a quadratic reconstruction error with an L1 penalty term on the code. The process is often too slow for applications such as real-time pattern recognition. We proposed two versions of a very fast algorithm that produces approximate estimates of the sparse code that can be used to compute good visual features, or to initialize exact iterative algorithms. The main idea is to train a non-linear, feed-forward predictor with a specific architecture and a fixed depth to produce the best possible approximation of the sparse code. A version of the method, which can be seen as a trainable version of Li and Osher's coordinate descent method, is shown to produce approximate solutions with 10 times less computation than Li and Osher's for the same approximation error. Unlike previous proposals for sparse code predictors, the system allows a kind of approximate ``explaining away'' to take place during inference. The resulting predictor is differentiable and can be included into globallytrained recognition systems.},
  language = {en},
  author = {Gregor, Karol and LeCun, Yann},
  pages = {8},
  file = {/Users/markwang/DropBox (MIT)/zotero/Gregor_LeCun_Learning Fast Approximations of Sparse Coding.pdf}
}

@article{donohoOptimallySparseRepresentation2003,
  title = {Optimally Sparse Representation in General (Nonorthogonal) Dictionaries via {$\mathscr{l}$}1 Minimization},
  volume = {100},
  copyright = {Copyright \textcopyright{} 2003, The National Academy of Sciences},
  issn = {0027-8424, 1091-6490},
  abstract = {Given a dictionary D = \{dk\} of vectors dk, we seek to represent a signal S as a linear combination S = {$\sum$}k {$\gamma$}(k)dk, with scalar coefficients {$\gamma$}(k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the {$\mathscr{l}$}1 norm of the coefficients {$\gamma\underbar$}. In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.},
  language = {en},
  number = {5},
  journal = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0437847100},
  author = {Donoho, David L. and Elad, Michael},
  month = mar,
  year = {2003},
  pages = {2197-2202},
  file = {/Users/markwang/DropBox (MIT)/zotero/Donoho_Elad_2003_Optimally sparse representation in general (nonorthogonal) dictionaries via â„“1 minimization.pdf;/Users/markwang/Zotero/storage/M9BQR9UM/2197.html},
  pmid = {16576749}
}

@inproceedings{beckFastIterativeShrinkageThresholding2009,
  title = {A Fast {{Iterative Shrinkage}}-{{Thresholding Algorithm}} with Application to Wavelet-Based Image Deblurring},
  abstract = {We consider the class of Iterative Shrinkage-Thresholding Algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods is attractive due to its simplicity, however, they are also known to converge quite slowly. In this paper we present a Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) which preserves the computational simplicity of ISTA, but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA.},
  booktitle = {2009 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  doi = {10.1109/ICASSP.2009.4959678},
  author = {Beck, A. and Teboulle, M.},
  month = apr,
  year = {2009},
  keywords = {Inverse problems,Signal processing algorithms,Image restoration,Convergence,image restoration,wavelet transforms,Acceleration,fast iterative shrinkage-thresholding algorithm,image deblurring,Iterative algorithms,iterative methods,Iterative methods,iterative shrinkage-thresholding algorithm,least squares,least squares and l1 regularization problems,Least squares approximation,optimal gradient method,Signal processing,signal/image processing,Sparse matrices,two steps iterative algorithms,wavelet-based image deblurring},
  pages = {693-696},
  file = {/Users/markwang/DropBox (MIT)/zotero/Beck_Teboulle_2009_A fast Iterative Shrinkage-Thresholding Algorithm with application to wavelet-based image deblurring.pdf;/Users/markwang/Zotero/storage/FF3BVFTM/4959678.html}
}

@article{mardaniNeuralProximalGradient2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.03963},
  primaryClass = {cs},
  title = {Neural {{Proximal Gradient Descent}} for {{Compressive Imaging}}},
  abstract = {Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. Learning a good inverse mapping from training data faces severe challenges, including: (i) scarcity of training data; (ii) need for plausible reconstructions that are physically feasible; (iii) need for fast reconstruction, especially in real-time applications. We develop a successful system solving all these challenges, using as basic architecture the recurrent application of proximal gradient algorithm. We learn a proximal map that works well with real images based on residual networks. Contraction of the resulting map is analyzed, and incoherence conditions are investigated that drive the convergence of the iterates. Extensive experiments are carried out under different settings: (a) reconstructing abdominal MRI of pediatric patients from highly undersampled Fourier-space data and (b) superresolving natural face images. Our key findings include: 1. a recurrent ResNet with a single residual block unrolled from an iterative algorithm yields an effective proximal which accurately reveals MR image details. 2. Our architecture significantly outperforms conventional non-recurrent deep ResNets by 2dB SNR; it is also trained much more rapidly. 3. It outperforms state-of-the-art compressed-sensing Wavelet-based methods by 4dB SNR, with 100x speedups in reconstruction time.},
  journal = {arXiv:1806.03963 [cs]},
  author = {Mardani, Morteza and Sun, Qingyun and Vasawanala, Shreyas and Papyan, Vardan and Monajemi, Hatef and Pauly, John and Donoho, David},
  month = jun,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Mardani et al_2018_Neural Proximal Gradient Descent for Compressive Imaging.pdf;/Users/markwang/Zotero/storage/EQI724KX/1806.html}
}

@inproceedings{aggarwalModelBasedImage2018,
  title = {Model Based Image Reconstruction Using Deep Learned Priors ({{MODL}})},
  abstract = {We introduce a model-based image reconstruction framework, where we use a deep convolution neural network (CNN) based regularization prior. We rely on a recursive algorithm, which alternates between a CNN based denoising step and enforcement of data consistency. Unrolling the recursive algorithm yields a deep network that is trained using backpropagation. The unique aspect of this method is the use of the same CNN weights at each iteration, which makes the resulting structure consistent with the model-based formulation. Also, this approach reduces the number of trainable parameters, which hence lower the amount of training data needed. The use of a forward model also reduces the size of the network and enables the exploitation additional prior information available from calibration data. The use of the framework for multichannel MRI reconstruction provides improved reconstructions, compared to other state-of-the-art methods.},
  booktitle = {2018 {{IEEE}} 15th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2018)},
  doi = {10.1109/ISBI.2018.8363663},
  author = {Aggarwal, H. K. and Mani, M. P. and Jacob, M.},
  month = apr,
  year = {2018},
  keywords = {Image reconstruction,image reconstruction,image denoising,Noise reduction,Data models,iterative methods,calibration data,CNN based regularization prior,CNN weights,Computer architecture,convolutional neural network,data consistency,deep convolution neural network,Deep learning,deep network,forward model,image reconstruction framework,Magnetic resonance imaging,model based image reconstruction using deep learned priors,multichannel MRI reconstruction,neural nets,parallel imaging,recursive algorithm,Sensitivity,Training,training data},
  pages = {671-674},
  file = {/Users/markwang/DropBox (MIT)/zotero/Aggarwal et al_2018_Model based image reconstruction using deep learned priors (MODL).pdf;/Users/markwang/Zotero/storage/Z7FKX233/8363663.html}
}

@article{zhangISTANetInterpretableOptimizationInspired2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07929},
  primaryClass = {cs},
  title = {{{ISTA}}-{{Net}}: {{Interpretable Optimization}}-{{Inspired Deep Network}} for {{Image Compressive Sensing}}},
  shorttitle = {{{ISTA}}-{{Net}}},
  abstract = {With the aim of developing a fast yet accurate algorithm for compressive sensing (CS) reconstruction of natural images, we combine in this paper the merits of two existing categories of CS methods: the structure insights of traditional optimization-based methods and the speed of recent network-based ones. Specifically, we propose a novel structured deep network, dubbed ISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm (ISTA) for optimizing a general \$\textbackslash{}ell\_1\$ norm CS reconstruction model. To cast ISTA into deep network form, we develop an effective strategy to solve the proximal mapping associated with the sparsity-inducing regularizer using nonlinear transforms. All the parameters in ISTA-Net (\textbackslash{}eg nonlinear transforms, shrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than being hand-crafted. Moreover, considering that the residuals of natural images are more compressible, an enhanced version of ISTA-Net in the residual domain, dubbed \{ISTA-Net\}\$\^+\$, is derived to further improve CS reconstruction. Extensive CS experiments demonstrate that the proposed ISTA-Nets outperform existing state-of-the-art optimization-based and network-based CS methods by large margins, while maintaining fast computational speed. Our source codes are available: \textbackslash{}textsl\{http://jianzhang.tech/projects/ISTA-Net\}.},
  journal = {arXiv:1706.07929 [cs]},
  author = {Zhang, Jian and Ghanem, Bernard},
  month = jun,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Multimedia},
  file = {/Users/markwang/DropBox (MIT)/zotero/Zhang_Ghanem_2017_ISTA-Net - Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing.pdf;/Users/markwang/Zotero/storage/IE4JDB94/1706.html}
}

@article{heDeepResidualLearning2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  primaryClass = {cs},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  journal = {arXiv:1512.03385 [cs]},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  month = dec,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/He et al_2015_Deep Residual Learning for Image Recognition.pdf;/Users/markwang/Zotero/storage/NGHW8XEH/1512.html}
}

@article{yangADMMNetDeepLearning2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.06869},
  primaryClass = {cs},
  title = {{{ADMM}}-{{Net}}: {{A Deep Learning Approach}} for {{Compressive Sensing MRI}}},
  shorttitle = {{{ADMM}}-{{Net}}},
  abstract = {Compressive sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR images from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and speed, in this paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and generalized versions. ADMM-Nets are defined over data flow graphs, which are derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They take the sampled k-space data as inputs and output reconstructed MR images. Moreover, we extend our network to cope with complex-valued MR images. In the training phase, all parameters of the nets, e.g., transforms, shrinkage functions, etc., are discriminatively trained end-to-end. In the testing phase, they have computational overhead similar to ADMM algorithm but use optimized parameters learned from the data for CS-based reconstruction task. We investigate different configurations in network structures and conduct extensive experiments on MR image reconstruction under different sampling rates. Due to the combination of the advantages in model-based approach and deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction accuracies with fast computational speed.},
  journal = {arXiv:1705.06869 [cs]},
  author = {Yang, Yan and Sun, Jian and Li, Huibin and Xu, Zongben},
  month = may,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/DropBox (MIT)/zotero/Yang et al_2017_ADMM-Net - A Deep Learning Approach for Compressive Sensing MRI.pdf;/Users/markwang/Zotero/storage/BXBYGUTH/1705.html}
}

@article{xieDifferentiableLinearizedADMM2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.06179},
  primaryClass = {cs, stat},
  title = {Differentiable {{Linearized ADMM}}},
  abstract = {Recently, a number of learning-based optimization methods that combine data-driven architectures with the classical optimization algorithms have been proposed and explored, showing superior empirical performance in solving various ill-posed inverse problems, but there is still a scarcity of rigorous analysis about the convergence behaviors of learning-based optimization. In particular, most existing analyses are specific to unconstrained problems but cannot apply to the more general cases where some variables of interest are subject to certain constraints. In this paper, we propose Differentiable Linearized ADMM (D-LADMM) for solving the problems with linear constraints. Specifically, D-LADMM is a K-layer LADMM inspired deep neural network, which is obtained by firstly introducing some learnable weights in the classical Linearized ADMM algorithm and then generalizing the proximal operator to some learnable activation function. Notably, we rigorously prove that there exist a set of learnable parameters for D-LADMM to generate globally converged solutions, and we show that those desired parameters can be attained by training D-LADMM in a proper way. To the best of our knowledge, we are the first to provide the convergence analysis for the learning-based optimization method on constrained problems.},
  journal = {arXiv:1905.06179 [cs, stat]},
  author = {Xie, Xingyu and Wu, Jianlong and Zhong, Zhisheng and Liu, Guangcan and Lin, Zhouchen},
  month = may,
  year = {2019},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/markwang/DropBox (MIT)/zotero/Xie et al_2019_Differentiable Linearized ADMM.pdf;/Users/markwang/Zotero/storage/BB6PIWRK/1905.html}
}

@inproceedings{liuALISTAAnalyticWeights2019,
  title = {{{ALISTA}}: {{Analytic Weights Are As Good As Learned Weights}} in {{LISTA}}},
  shorttitle = {{{ALISTA}}},
  abstract = {Deep neural networks based on unfolding an iterative algorithm, for example, LISTA (learned iterative shrinkage thresholding algorithm), have been an empirical success for sparse signal recovery. The weights of these neural networks are currently determined by data-driven ``black-box'' training. In this work, we propose Analytic LISTA (ALISTA), where the weight matrix in LISTA is computed as the solution to a data-free optimization problem, leaving only the stepsize and threshold parameters to data-driven learning. This significantly simplifies the training. Specifically, the data-free optimization problem is based on coherence minimization. We show our ALISTA retains the optimal linear convergence proved in (Chen et al., 2018) and has a performance comparable to LISTA. Furthermore, we extend ALISTA to convolutional linear operators, again determined in a data-free manner. We also propose a feed-forward framework that combines the data-free optimization and ALISTA networks from end to end, one that can be jointly trained to gain robustness to small perturbations in the encoding model.},
  booktitle = {{{ICLR}} 2019},
  author = {Liu, Jialin and Chen, Xiaohan and Wang, Zhangyang and Yin, Wotao},
  year = {2019},
  keywords = {Algorithm,Sparse matrix,Optimization problem,Artificial neural network,Black box,Detection theory,Entityâ€“relationship model,Iterative method,Mathematical optimization,Neural Network Simulation,Perturbation theory,Rate of convergence,Unfolding (DSP implementation),Weight},
  file = {/Users/markwang/DropBox (MIT)/zotero/Liu et al_2019_ALISTA - Analytic Weights Are As Good As Learned Weights in LISTA.pdf}
}

@inproceedings{ryuPlugandPlayMethodsProvably2019,
  title = {Plug-and-{{Play Methods Provably Converge}} with {{Properly Trained Denoisers}}},
  abstract = {Plug-and-play (PnP) is a non-convex framework that integrates modern denoising priors, such as BM3D or deep learning-based denoisers, into ADMM or other proximal algorithms. An advantage of PnP is ...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Ryu, Ernest and Liu, Jialin and Wang, Sicheng and Chen, Xiaohan and Wang, Zhangyang and Yin, Wotao},
  month = may,
  year = {2019},
  pages = {5546-5557},
  file = {/Users/markwang/DropBox (MIT)/zotero/Ryu et al_2019_Plug-and-Play Methods Provably Converge with Properly Trained Denoisers.pdf;/Users/markwang/Zotero/storage/A7GP4L26/ryu19a.html}
}

@article{miyatoSpectralNormalizationGenerative2018,
  title = {Spectral {{Normalization}} for {{Generative Adversarial Networks}}},
  abstract = {One of the challenges in the study of generative adversarial networks is the instability of its training. 
  In this paper, we propose a novel weight normalization technique called spectral...},
  author = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  month = feb,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Miyato et al_2018_Spectral Normalization for Generative Adversarial Networks.pdf;/Users/markwang/Zotero/storage/PBEPIXUX/forum.html}
}

@article{salimansImprovedTechniquesTraining2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.03498},
  primaryClass = {cs},
  title = {Improved {{Techniques}} for {{Training GANs}}},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  journal = {arXiv:1606.03498 [cs]},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  month = jun,
  year = {2016},
  keywords = {Computer Science - Machine Learning,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/markwang/DropBox (MIT)/zotero/Salimans et al_2016_Improved Techniques for Training GANs.pdf;/Users/markwang/Zotero/storage/6PSB3X2C/1606.html}
}

@article{ronnebergerUNetConvolutionalNetworks2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.04597},
  primaryClass = {cs},
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  journal = {arXiv:1505.04597 [cs]},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  month = may,
  year = {2015},
  file = {/Users/markwang/DropBox (MIT)/zotero/Ronneberger et al_2015_U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf}
}

@inproceedings{tanJointDemosaicingDenoising2017,
  title = {Joint Demosaicing and Denoising of Noisy Bayer Images with {{ADMM}}},
  abstract = {Image demosaicing and denoising are import steps of image signal processing. Sequential executions of demosaicing and denoising have essential drawbacks that they degrade the results of each other. Joint demosaicing and denoising overcomes the difficulties by solving the two problems in one model. This paper introduces a unified object function with hidden priors and a variant of ADMM to recover a full-resolution color image with a noisy Bayer input. Experimental results demonstrate that our method performs better than state-of-the-art methods in both PSNR comparison and human vision. In addition, our method is much more robust to variations of noise level.},
  doi = {10.1109/ICIP.2017.8296823},
  author = {Tan, Hanlin and Zeng, Xiangrong and Lai, Shiming and Liu, Yu and Zhang, Maojun},
  month = sep,
  year = {2017},
  file = {/Users/markwang/DropBox (MIT)/zotero/Tan et al_2017_Joint demosaicing and denoising of noisy bayer images with ADMM.pdf}
}

@inproceedings{fattalSingleImageDehazing2008,
  address = {{New York, NY, USA}},
  series = {{{SIGGRAPH}} '08},
  title = {Single {{Image Dehazing}}},
  isbn = {978-1-4503-0112-1},
  abstract = {In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation, the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In this new approach we formulate a refined image formation model that accounts for surface shading in addition to the transmission function. This allows us to resolve ambiguities in the data by searching for a solution in which the resulting shading and transmission functions are locally statistically uncorrelated. A similar principle is used to estimate the color of the haze. Results demonstrate the new method abilities to remove the haze layer as well as provide a reliable transmission estimate which can be used for additional applications such as image refocusing and novel view synthesis.},
  booktitle = {{{ACM SIGGRAPH}} 2008 {{Papers}}},
  publisher = {{ACM}},
  doi = {10.1145/1399504.1360671},
  author = {Fattal, Raanan},
  year = {2008},
  pages = {72:1--72:9}
}

@article{ulyanovDeepImagePrior2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.10925},
  primaryClass = {cs, stat},
  title = {Deep {{Image Prior}}},
  abstract = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity. Code and supplementary material are available at https://dmitryulyanov.github.io/deep\_image\_prior .},
  journal = {arXiv:1711.10925 [cs, stat]},
  author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  month = nov,
  year = {2017},
  file = {/Users/markwang/DropBox (MIT)/zotero/Ulyanov et al_2017_Deep Image Prior.pdf}
}

@inproceedings{guBriefReviewImage2018,
  title = {A Brief Review of Image Denoising Algorithms and Beyond},
  abstract = {The recent advances in hardware and imaging systems made the digital cameras ubiquitous.Although the development of hardware has steadily improved the quality of images for the last several decades, image degradation is unavoidable due to the many factors affecting the image acquisition process and the subsequent postprocessing. Image denoising, which aims to reconstruct a high quality image from its degraded observation, is a classical yet still very active topic in the area of lowlevel computer vision. It represents an important building block in real applications such as digital photography, medical image analysis, remote sensing, surveillance and digital entertainment. Also, image denoising constitutes an ideal test bed for evaluating image prior modeling methods. In this paper, we briefly review recent progresses in image denoising. We firstly present an overview of prior modeling approaches used in image denoising task. Then, we review conventional sparse representation based denoising algorithms, low-rank based denoising algorithms and recently proposed deep neural networks based approaches. At last, we discuss some emerging topics and open problems about image denoising.},
  author = {Gu, Shuhang and Timofte, Radu},
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Gu_Timofte_2018_A brief review of image denoising algorithms and beyond.pdf}
}

@article{guoConvolutionalBlindDenoising2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1807.04686},
  primaryClass = {cs},
  title = {Toward {{Convolutional Blind Denoising}} of {{Real Photographs}}},
  abstract = {While deep convolutional neural networks (CNNs) have achieved impressive success in image denoising with additive white Gaussian noise (AWGN), their performance remains limited on real-world noisy photographs. The main reason is that their learned models are easy to overfit on the simplified AWGN model which deviates severely from the complicated real-world noise model. In order to improve the generalization ability of deep CNN denoisers, we suggest training a convolutional blind denoising network (CBDNet) with more realistic noise model and real-world noisy-clean image pairs. On the one hand, both signal-dependent noise and in-camera signal processing pipeline is considered to synthesize realistic noisy images. On the other hand, real-world noisy photographs and their nearly noise-free counterparts are also included to train our CBDNet. To further provide an interactive strategy to rectify denoising result conveniently, a noise estimation subnetwork with asymmetric learning to suppress under-estimation of noise level is embedded into CBDNet. Extensive experimental results on three datasets of real-world noisy photographs clearly demonstrate the superior performance of CBDNet over state-of-the-arts in terms of quantitative metrics and visual quality. The code has been made available at https://github.com/GuoShi28/CBDNet.},
  journal = {arXiv:1807.04686 [cs]},
  author = {Guo, Shi and Yan, Zifei and Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},
  month = jul,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Guo et al_2018_Toward Convolutional Blind Denoising of Real Photographs.pdf}
}

@article{lehtinenNoise2NoiseLearningImage2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.04189},
  primaryClass = {cs, stat},
  title = {{{Noise2Noise}}: {{Learning Image Restoration}} without {{Clean Data}}},
  shorttitle = {{{Noise2Noise}}},
  abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans -- all corrupted by different processes -- based on noisy data only.},
  journal = {arXiv:1803.04189 [cs, stat]},
  author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
  month = mar,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Lehtinen et al_2018_Noise2Noise - Learning Image Restoration without Clean Data.pdf}
}

@article{gemanConstrainedRestorationRecovery1992,
  title = {Constrained Restoration and the Recovery of Discontinuities},
  volume = {14},
  issn = {0162-8828},
  abstract = {The linear image restoration problem is to recover an original brightness distribution X/sup 0/ given the blurred and noisy observations Y=KX/sup 0/+B, where K and B represent the point spread function and measurement error, respectively. This problem is typical of ill-conditioned inverse problems that frequently arise in low-level computer vision. A conventional method to stabilize the problem is to introduce a priori constraints on X/sup 0/ and design a cost functional H(X) over images X, which is a weighted average of the prior constraints (regularization term) and posterior constraints (data term); the reconstruction is then the image X, which minimizes H. A prominent weakness in this approach, especially with quadratic-type stabilizers, is the difficulty in recovering discontinuities. The authors therefore examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity. In this sense, discontinuities are addressed implicitly rather than explicitly.{$<>$}},
  number = {3},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/34.120331},
  author = {Geman, D. and Reynolds, G.},
  month = mar,
  year = {1992},
  keywords = {half quadratic splitting},
  pages = {367-383},
  file = {/Users/markwang/DropBox (MIT)/zotero/Geman_Reynolds_1992_Constrained restoration and the recovery of discontinuities.pdf}
}

@article{gemanNonlinearImageRecovery1995,
  title = {Nonlinear Image Recovery with Half-Quadratic Regularization},
  volume = {4},
  issn = {1057-7149},
  abstract = {One popular method for the recovery of an ideal intensity image from corrupted or indirect measurements is regularization: minimize an objective function that enforces a roughness penalty in addition to coherence with the data. Linear estimates are relatively easy to compute but generally introduce systematic errors; for example, they are incapable of recovering discontinuities and other important image attributes. In contrast, nonlinear estimates are more accurate but are often far less accessible. This is particularly true when the objective function is nonconvex, and the distribution of each data component depends on many image components through a linear operator with broad support. Our approach is based on an auxiliary array and an extended objective function in which the original variables appear quadratically and the auxiliary variables are decoupled. Minimizing over the auxiliary array alone yields the original function so that the original image estimate can be obtained by joint minimization. This can be done efficiently by Monte Carlo methods, for example by FFT-based annealing using a Markov chain that alternates between (global) transitions from one array to the other. Experiments are reported in optical astronomy, with space telescope data, and computed tomography.{$<>$}},
  number = {7},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/83.392335},
  author = {Geman, D. and {Chengda Yang}},
  month = jul,
  year = {1995},
  pages = {932-946},
  file = {/Users/markwang/DropBox (MIT)/zotero/Geman_Chengda Yang_1995_Nonlinear image recovery with half-quadratic regularization.pdf}
}

@inproceedings{schmidtShrinkageFieldsEffective2014,
  title = {Shrinkage {{Fields}} for {{Effective Image Restoration}}},
  abstract = {Many state-of-the-art image restoration approaches do not scale well to larger images, such as megapixel images common in the consumer segment. Computationally expensive optimization is often the culprit. While efficient alternatives exist, they have not reached the same level of image quality. The goal of this paper is to develop an effective approach to image restoration that offers both computational efficiency and high restoration quality. To that end we propose shrinkage fields, a random field-based architecture that combines the image model and the optimization algorithm in a single unit. The underlying shrinkage operation bears connections to wavelet approaches, but is used here in a random field context. Computational efficiency is achieved by construction through the use of convolution and DFT as the core components, high restoration quality is attained through loss-based training of all model parameters and the use of a cascade architecture. Unlike heavily engineered solutions, our learning approach can be adapted easily to different trade-offs between efficiency and image quality. We demonstrate state-of-the-art restoration results with high levels of computational efficiency, and significant speedup potential through inherent parallelism.},
  booktitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  doi = {10.1109/CVPR.2014.349},
  author = {Schmidt, U. and Roth, S.},
  month = jun,
  year = {2014},
  pages = {2774-2781},
  file = {/Users/markwang/DropBox (MIT)/zotero/Schmidt_Roth_2014_Shrinkage Fields for Effective Image Restoration.pdf}
}

@article{chenTrainableNonlinearReaction2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.02848},
  title = {Trainable {{Nonlinear Reaction Diffusion}}: {{A Flexible Framework}} for {{Fast}} and {{Effective Image Restoration}}},
  volume = {39},
  issn = {0162-8828, 2160-9292},
  shorttitle = {Trainable {{Nonlinear Reaction Diffusion}}},
  abstract = {Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (\ie, linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD -- Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.},
  number = {6},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2016.2596743},
  author = {Chen, Yunjin and Pock, Thomas},
  month = jun,
  year = {2017},
  pages = {1256-1272},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chen_Pock_2017_Trainable Nonlinear Reaction Diffusion - A Flexible Framework for Fast and Effective Image Restoration.pdf}
}





@article{zhangGaussianDenoiserResidual2017,
  title = {Beyond a {{Gaussian Denoiser}}: {{Residual Learning}} of {{Deep CNN}} for {{Image Denoising}}},
  volume = {26},
  issn = {1057-7149},
  shorttitle = {Beyond a {{Gaussian Denoiser}}},
  abstract = {The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks, such as Gaussian denoising, single image super-resolution, and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.},
  number = {7},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2017.2662206},
  author = {Zhang, K. and Zuo, W. and Chen, Y. and Meng, D. and Zhang, L.},
  month = jul,
  year = {2017},
  pages = {3142-3155},
  file = {/Users/markwang/DropBox (MIT)/zotero/Zhang et al_2017_Beyond a Gaussian Denoiser - Residual Learning of Deep CNN for Image Denoising.pdf}
}

@inproceedings{abdelhamedHighQualityDenoisingDataset2018,
  title = {A {{High}}-{{Quality Denoising Dataset}} for {{Smartphone Cameras}}},
  doi = {10.1109/CVPR.2018.00182},
  author = {Abdelhamed, Abdelrahman and Lin, Stephen and S. Brown, Michael},
  month = jun,
  year = {2018},
  pages = {1692-1700}
}

@inproceedings{fuRemovingRainSingle2017,
  title = {Removing {{Rain}} from {{Single Images}} via a {{Deep Detail Network}}},
  abstract = {We propose a new deep network architecture for removing rain streaks from individual images based on the deep convolutional neural network (CNN). Inspired by the deep residual network (ResNet) that simplifies the learning process by changing the mapping form, we propose a deep detail network to directly reduce the mapping range from input to output, which makes the learning process easier. To further improve the de-rained result, we use a priori image domain knowledge by focusing on high frequency detail during training, which removes background interference and focuses the model on the structure of rain in images. This demonstrates that a deep architecture not only has benefits for high-level vision tasks but also can be used to solve low-level imaging problems. Though we train the network on synthetic data, we find that the learned network generalizes well to real-world test images. Experiments show that the proposed method significantly outperforms state-of-the-art methods on both synthetic and real-world images in terms of both qualitative and quantitative measures. We discuss applications of this structure to denoising and JPEG artifact reduction at the end of the paper.},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  doi = {10.1109/CVPR.2017.186},
  author = {Fu, X. and Huang, J. and Zeng, D. and Huang, Y. and Ding, X. and Paisley, J.},
  month = jul,
  year = {2017},
  pages = {1715-1723},
  file = {/Users/markwang/DropBox (MIT)/zotero/Fu et al_2017_Removing Rain from Single Images via a Deep Detail Network.pdf}
}

@article{dabovImageDenoisingSparse2007,
  title = {Image {{Denoising}} by {{Sparse}} 3-{{D Transform}}-{{Domain Collaborative Filtering}}},
  volume = {16},
  issn = {1057-7149},
  abstract = {We propose a novel image denoising strategy based on an enhanced sparse representation in transform domain. The enhancement of the sparsity is achieved by grouping similar 2D image fragments (e.g., blocks) into 3D data arrays which we call "groups." Collaborative Altering is a special procedure developed to deal with these 3D groups. We realize it using the three successive steps: 3D transformation of a group, shrinkage of the transform spectrum, and inverse 3D transformation. The result is a 3D estimate that consists of the jointly filtered grouped image blocks. By attenuating the noise, the collaborative filtering reveals even the finest details shared by grouped blocks and, at the same time, it preserves the essential unique features of each individual block. The filtered blocks are then returned to their original positions. Because these blocks are overlapping, for each pixel, we obtain many different estimates which need to be combined. Aggregation is a particular averaging procedure which is exploited to take advantage of this redundancy. A significant improvement is obtained by a specially developed collaborative Wiener filtering. An algorithm based on this novel denoising strategy and its efficient implementation are presented in full detail; an extension to color-image denoising is also developed. The experimental results demonstrate that this computationally scalable algorithm achieves state-of-the-art denoising performance in terms of both peak signal-to-noise ratio and subjective visual quality.},
  number = {8},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2007.901238},
  author = {Dabov, K. and Foi, A. and Katkovnik, V. and Egiazarian, K.},
  month = aug,
  year = {2007},
  pages = {2080-2095},
  file = {/Users/markwang/DropBox (MIT)/zotero/Dabov et al_2007_Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering.pdf}
}

@inproceedings{mirdehghanOptimalStructuredLight2018,
  title = {Optimal {{Structured Light}} a La {{Carte}}},
  abstract = {We consider the problem of automatically generating sequences of structured-light patterns for active stereo triangulation of a static scene. Unlike existing approaches that use predetermined patterns and reconstruction algorithms tied to them, we generate patterns on the fly in response to generic specifications: number of patterns, projector-camera arrangement, workspace constraints, spatial frequency content, etc. Our pattern sequences are specifically optimized to minimize the expected rate of correspondence errors under those specifications for an unknown scene, and are coupled to a sequence-independent algorithm for perpixel disparity estimation. To achieve this, we derive an objective function that is easy to optimize and follows from first principles within a maximum-likelihood framework. By minimizing it, we demonstrate automatic discovery of pattern sequences, in under three minutes on a laptop, that can outperform state-of-the-art triangulation techniques.},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  doi = {10.1109/CVPR.2018.00654},
  author = {Mirdehghan, P. and Chen, W. and Kutulakos, K. N.},
  month = jun,
  year = {2018},
  pages = {6248-6257},
  file = {/Users/markwang/DropBox (MIT)/zotero/Mirdehghan et al_2018_Optimal Structured Light a la Carte.pdf}
}

@article{heideNonlineofsightImagingPartial2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.07134},
  primaryClass = {cs},
  title = {Non-Line-of-Sight {{Imaging}} with {{Partial Occluders}} and {{Surface Normals}}},
  abstract = {Imaging objects obscured by occluders is a significant challenge for many applications. A camera that could "see around corners" could help improve navigation and mapping capabilities of autonomous vehicles or make search and rescue missions more effective. Time-resolved single-photon imaging systems have recently been demonstrated to record optical information of a scene that can lead to an estimation of the shape and reflectance of objects hidden from the line of sight of a camera. However, existing non-line-of-sight (NLOS) reconstruction algorithms have been constrained in the types of light transport effects they model for the hidden scene parts. We introduce a factored NLOS light transport representation that accounts for partial occlusions and surface normals. Based on this model, we develop a factorization approach for inverse time-resolved light transport and demonstrate high-fidelity NLOS reconstructions for challenging scenes both in simulation and with an experimental NLOS imaging system.},
  journal = {arXiv:1711.07134 [cs]},
  author = {Heide, Felix and O'Toole, Matthew and Zang, Kai and Lindell, David and Diamond, Steven and Wetzstein, Gordon},
  month = nov,
  year = {2017},
  file = {/Users/markwang/DropBox (MIT)/zotero/Heide et al_2017_Non-line-of-sight Imaging with Partial Occluders and Surface Normals.pdf}
}

@inproceedings{scharsteinHighaccuracyStereoDepth2003,
  address = {{Madison, WI, USA}},
  title = {High-Accuracy Stereo Depth Maps Using Structured Light},
  isbn = {978-0-7695-1900-5},
  abstract = {Recent progress in stereo algorithm performance is quickly outpacing the ability of existing stereo data sets to discriminate among the best-performing algorithms, motivating the need for more challenging scenes with accurate ground truth information. This paper describes a method for acquiring high-complexity stereo image pairs with pixel-accurate correspondence information using structured light. Unlike traditional range-sensing approaches, our method does not require the calibration of the light sources and yields registered disparity maps between all pairs of cameras and illumination projectors. We present new stereo data sets acquired with our method and demonstrate their suitability for stereo algorithm evaluation. Our results are available at http://www.middlebury.edu/stereo/.},
  language = {en},
  booktitle = {2003 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}, 2003. {{Proceedings}}.},
  publisher = {{IEEE Comput. Soc}},
  doi = {10.1109/CVPR.2003.1211354},
  author = {Scharstein, D. and Szeliski, R.},
  year = {2003},
  pages = {I-195-I-202},
  file = {/Users/markwang/DropBox (MIT)/zotero/Scharstein_Szeliski_2003_High-accuracy stereo depth maps using structured light.pdf}
}

@inproceedings{scharsteinLearningConditionalRandom2007,
  title = {Learning {{Conditional Random Fields}} for {{Stereo}}},
  abstract = {State-of-the-art stereo vision algorithms utilize color changes as important cues for object boundaries. Most methods impose heuristic restrictions or priors on disparities, for example by modulating local smoothness costs with intensity gradients. In this paper we seek to replace such heuristics with explicit probabilistic models of disparities and intensities learned from real images. We have constructed a large number of stereo datasets with ground-truth disparities, and we use a subset of these datasets to learn the parameters of conditional random fields (CRFs). We present experimental results illustrating the potential of our approach for automatically learning the parameters of models with richer structure than standard hand-tuned MRF models.},
  booktitle = {2007 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  doi = {10.1109/CVPR.2007.383191},
  author = {Scharstein, D. and Pal, C.},
  month = jun,
  year = {2007},
  pages = {1-8},
  file = {/Users/markwang/DropBox (MIT)/zotero/Scharstein_Pal_2007_Learning Conditional Random Fields for Stereo.pdf}
}

@article{boykovFastApproximateEnergy2001,
  title = {Fast Approximate Energy Minimization via Graph Cuts},
  volume = {23},
  abstract = {Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. The authors consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is NP-hard even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.},
  number = {11},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/34.969114},
  author = {Boykov, Y. and Veksler, O. and Zabih, R.},
  month = nov,
  year = {2001},
  pages = {1222-1239},
  file = {/Users/markwang/DropBox (MIT)/zotero/Boykov et al_2001_Fast approximate energy minimization via graph cuts.pdf}
}

@article{jiansunStereoMatchingUsing2003,
  title = {Stereo Matching Using Belief Propagation},
  volume = {25},
  abstract = {In this paper, we formulate the stereo matching problem as a Markov network and solve it using Bayesian belief propagation. The stereo Markov network consists of three coupled Markov random fields that model the following: a smooth field for depth/disparity, a line process for depth discontinuity, and a binary process for occlusion. After eliminating the line process and the binary process by introducing two robust functions, we apply the belief propagation algorithm to obtain the maximum a posteriori (MAP) estimation in the Markov network. Other low-level visual cues (e.g., image segmentation) can also be easily incorporated in our stereo model to obtain better stereo results. Experiments demonstrate that our methods are comparable to the state-of-the-art stereo algorithms for many test cases.},
  number = {7},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2003.1206509},
  author = {{Jian Sun} and {Nan-Ning Zheng} and {Heung-Yeung Shum}},
  month = jul,
  year = {2003},
  pages = {787-800},
  file = {/Users/markwang/DropBox (MIT)/zotero/Jian Sun et al_2003_Stereo matching using belief propagation.pdf}
}

@inproceedings{tappenComparisonGraphCuts2003,
  title = {Comparison of Graph Cuts with Belief Propagation for Stereo, Using Identical {{MRF}} Parameters},
  abstract = {Recent stereo algorithms have achieved impressive results by modelling the disparity image as a Markov Random Field (MRF). An important component of an MRF-based approach is the inference algorithm used to find the most likely setting of each node in the MRF. Algorithms have been proposed which use graph cuts or belief propagation for inference. These stereo algorithms differ in both the inference algorithm used and the formulation of the MRF. It is unknown whether to attribute the responsibility for differences in performance to the MRF or the inference algorithm. We address this through controlled experiments by comparing the belief propagation algorithm and the graph cuts algorithm on the same MRF's, which have been created for calculating stereo disparities. We find that the labellings produced by the two algorithms are comparable. The solutions produced by graph cuts have a lower energy than those produced with belief propagation, but this does not necessarily lead to increased performance relative to the ground truth.},
  booktitle = {Proceedings {{Ninth IEEE International Conference}} on {{Computer Vision}}},
  doi = {10.1109/ICCV.2003.1238444},
  author = {{Tappen} and {Freeman}},
  month = oct,
  year = {2003},
  pages = {900-906 vol.2},
  file = {/Users/markwang/DropBox (MIT)/zotero/Tappen_Freeman_2003_Comparison of graph cuts with belief propagation for stereo, using identical MRF parameters.pdf}
}

@article{gengStructuredlight3DSurface2011,
  title = {Structured-Light {{3D}} Surface Imaging: A Tutorial},
  volume = {3},
  copyright = {\&\#169; 2011 OSA},
  issn = {1943-8206},
  shorttitle = {Structured-Light {{3D}} Surface Imaging},
  abstract = {We provide a review of recent advances in 3D surface imaging technologies. We focus particularly on noncontact 3D surface measurement techniques based on structured illumination. The high-speed and high-resolution pattern projection capability offered by the digital light projection technology, together with the recent advances in imaging sensor technologies, may enable new generation systems for 3D surface measurement applications that will provide much better functionality and performance than existing ones in terms of speed, accuracy, resolution, modularization, and ease of use. Performance indexes of 3D imaging system are discussed, and various 3D surface imaging schemes are categorized, illustrated, and compared. Calibration techniques are also discussed, since they play critical roles in achieving the required precision. Numerous applications of 3D surface imaging technologies are discussed with several examples.},
  language = {EN},
  number = {2},
  journal = {Advances in Optics and Photonics},
  doi = {10.1364/AOP.3.000128},
  author = {Geng, Jason},
  month = jun,
  year = {2011},
  pages = {128-160},
  file = {/Users/markwang/DropBox (MIT)/zotero/Geng_2011_Structured-light 3D surface imaging - a tutorial.pdf}
}

@article{bhoiMonocularDepthEstimation2019a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1901.09402},
  title = {Monocular {{Depth Estimation}}: {{A Survey}}},
  volume = {abs/1901.09402},
  shorttitle = {Monocular {{Depth Estimation}}},
  abstract = {Monocular depth estimation is often described as an ill-posed and inherently ambiguous problem. Estimating depth from 2D images is a crucial step in scene reconstruction, 3Dobject recognition, segmentation, and detection. The problem can be framed as: given a single RGB image as input, predict a dense depth map for each pixel. This problem is worsened by the fact that most scenes have large texture and structural variations, object occlusions, and rich geometric detailing. All these factors contribute to difficulty in accurate depth estimation. In this paper, we review five papers that attempt to solve the depth estimation problem with various techniques including supervised, weakly-supervised, and unsupervised learning techniques. We then compare these papers and understand the improvements made over one another. Finally, we explore potential improvements that can aid to better solve this problem.},
  journal = {ArXiv},
  author = {Bhoi, Amlaan},
  year = {2019},
  file = {/Users/markwang/DropBox (MIT)/zotero/Bhoi_2019_Monocular Depth Estimation - A Survey2.pdf}
}

@article{eigenDepthMapPrediction2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1406.2283},
  primaryClass = {cs},
  title = {Depth {{Map Prediction}} from a {{Single Image}} Using a {{Multi}}-{{Scale Deep Network}}},
  abstract = {Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence suffices for estimation, finding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that refines this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.},
  journal = {arXiv:1406.2283 [cs]},
  author = {Eigen, David and Puhrsch, Christian and Fergus, Rob},
  month = jun,
  year = {2014},
  file = {/Users/markwang/DropBox (MIT)/zotero/Eigen et al_2014_Depth Map Prediction from a Single Image using a Multi-Scale Deep Network.pdf}
}

@article{liuLearningDepthSingle2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1502.07411},
  title = {Learning {{Depth}} from {{Single Monocular Images Using Deep Convolutional Neural Fields}}},
  volume = {38},
  issn = {0162-8828, 2160-9292},
  abstract = {In this article, we tackle the problem of depth estimation from single monocular images. Compared with depth estimation using multiple images such as stereo depth perception, depth from monocular images is much more challenging. Prior work typically focuses on exploiting geometric priors or additional sources of information, most using hand-crafted features. Recently, there is mounting evidence that features from deep convolutional neural networks (CNN) set new records for various vision applications. On the other hand, considering the continuous characteristic of the depth values, depth estimations can be naturally formulated as a continuous conditional random field (CRF) learning problem. Therefore, here we present a deep convolutional neural field model for estimating depths from single monocular images, aiming to jointly explore the capacity of deep CNN and continuous CRF. In particular, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. We then further propose an equally effective model based on fully convolutional networks and a novel superpixel pooling method, which is \$\textbackslash{}sim 10\$ times faster, to speedup the patch-wise convolutions in the deep model. With this more efficient model, we are able to design deeper networks to pursue better performance. Experiments on both indoor and outdoor scene datasets demonstrate that the proposed method outperforms state-of-the-art depth estimation approaches.},
  number = {10},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2015.2505283},
  author = {Liu, Fayao and Shen, Chunhua and Lin, Guosheng and Reid, Ian},
  month = oct,
  year = {2016},
  pages = {2024-2039},
  file = {/Users/markwang/DropBox (MIT)/zotero/Liu et al_2016_Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields.pdf}
}

@inproceedings{saxenaLearningDepthSingle2005,
  title = {Learning Depth from Single Monocular Images},
  abstract = {We consider the task of depth estimation from a single monocular image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a discriminatively-trained Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models both depths at individual points as well as the relation between depths at different points. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. 1},
  booktitle = {In {{NIPS}} 18},
  publisher = {{MIT Press}},
  author = {Saxena, Ashutosh and Chung, Sung H. and Ng, Andrew Y.},
  year = {2005},
  file = {/Users/markwang/DropBox (MIT)/zotero/Saxena et al_2005_Learning depth from single monocular images.pdf}
}

@article{godardUnsupervisedMonocularDepth2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.03677},
  primaryClass = {cs, stat},
  title = {Unsupervised {{Monocular Depth Estimation}} with {{Left}}-{{Right Consistency}}},
  abstract = {Learning based methods have shown very promising results for the task of depth estimation in single images. However, most existing approaches treat depth prediction as a supervised regression problem and as a result, require vast quantities of corresponding ground truth depth data for training. Just recording quality depth data in a range of environments is a challenging problem. In this paper, we innovate beyond existing approaches, replacing the use of explicit depth data during training with easier-to-obtain binocular stereo footage. We propose a novel training objective that enables our convolutional neural network to learn to perform single image depth estimation, despite the absence of ground truth depth data. Exploiting epipolar geometry constraints, we generate disparity images by training our network with an image reconstruction loss. We show that solving for image reconstruction alone results in poor quality depth images. To overcome this problem, we propose a novel training loss that enforces consistency between the disparities produced relative to both the left and right images, leading to improved performance and robustness compared to existing approaches. Our method produces state of the art results for monocular depth estimation on the KITTI driving dataset, even outperforming supervised methods that have been trained with ground truth depth.},
  journal = {arXiv:1609.03677 [cs, stat]},
  author = {Godard, Cl{\'e}ment and Mac Aodha, Oisin and Brostow, Gabriel J.},
  month = sep,
  year = {2016},
  file = {/Users/markwang/DropBox (MIT)/zotero/Godard et al_2016_Unsupervised Monocular Depth Estimation with Left-Right Consistency.pdf}
}

@article{godardDiggingSelfSupervisedMonocular2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.01260},
  primaryClass = {cs, stat},
  title = {Digging {{Into Self}}-{{Supervised Monocular Depth Estimation}}},
  abstract = {Per-pixel ground-truth depth data is challenging to acquire at scale. To overcome this limitation, self-supervised learning has emerged as a promising alternative for training models to perform monocular depth estimation. In this paper, we propose a set of improvements, which together result in both quantitatively and qualitatively improved depth maps compared to competing self-supervised methods. Research on self-supervised monocular training usually explores increasingly complex architectures, loss functions, and image formation models, all of which have recently helped to close the gap with fully-supervised methods. We show that a surprisingly simple model, and associated design choices, lead to superior predictions. In particular, we propose (i) a minimum reprojection loss, designed to robustly handle occlusions, (ii) a full-resolution multi-scale sampling method that reduces visual artifacts, and (iii) an auto-masking loss to ignore training pixels that violate camera motion assumptions. We demonstrate the effectiveness of each component in isolation, and show high quality, state-of-the-art results on the KITTI benchmark.},
  journal = {arXiv:1806.01260 [cs, stat]},
  author = {Godard, Cl{\'e}ment and Mac Aodha, Oisin and Firman, Michael and Brostow, Gabriel},
  month = jun,
  year = {2018},
  file = {/Users/markwang/DropBox (MIT)/zotero/Godard et al_2018_Digging Into Self-Supervised Monocular Depth Estimation.pdf}
}

@article{maSparseDepthSensing2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.01398},
  primaryClass = {cs},
  title = {Sparse {{Depth Sensing}} for {{Resource}}-{{Constrained Robots}}},
  abstract = {We consider the case in which a robot has to navigate in an unknown environment but does not have enough on-board power or payload to carry a traditional depth sensor (e.g., a 3D lidar) and thus can only acquire a few (point-wise) depth measurements. We address the following question: is it possible to reconstruct the geometry of an unknown environment using sparse and incomplete depth measurements? Reconstruction from incomplete data is not possible in general, but when the robot operates in man-made environments, the depth exhibits some regularity (e.g., many planar surfaces with only a few edges); we leverage this regularity to infer depth from a small number of measurements. Our first contribution is a formulation of the depth reconstruction problem that bridges robot perception with the compressive sensing literature in signal processing. The second contribution includes a set of formal results that ascertain the exactness and stability of the depth reconstruction in 2D and 3D problems, and completely characterize the geometry of the profiles that we can reconstruct. Our third contribution is a set of practical algorithms for depth reconstruction: our formulation directly translates into algorithms for depth estimation based on convex programming. In real-world problems, these convex programs are very large and general-purpose solvers are relatively slow. For this reason, we discuss ad-hoc solvers that enable fast depth reconstruction in real problems. The last contribution is an extensive experimental evaluation in 2D and 3D problems, including Monte Carlo runs on simulated instances and testing on multiple real datasets. Empirical results confirm that the proposed approach ensures accurate depth reconstruction, outperforms interpolation-based strategies, and performs well even when the assumption of structured environment is violated.},
  journal = {arXiv:1703.01398 [cs]},
  author = {Ma, Fangchang and Carlone, Luca and Ayaz, Ulas and Karaman, Sertac},
  month = mar,
  year = {2017},
  file = {/Users/markwang/DropBox (MIT)/zotero/Ma et al_2017_Sparse Depth Sensing for Resource-Constrained Robots.pdf}
}

@inproceedings{morenoEmbeddedPhaseShifting2015,
  title = {Embedded Phase Shifting: {{Robust}} Phase Shifting with Embedded Signals},
  shorttitle = {Embedded Phase Shifting},
  abstract = {We introduce Embedded PS, a new robust and accurate phase shifting algorithm for 3D scanning. The method projects only high frequency sinusoidal patterns in order to reduce errors due to global illumination effects, such as subsurface scattering and interreflections. The frequency set for the projected patterns is specially designed so that our algorithm can extract a set of embedded low frequency sinusoidals with simple math. All the signals, patterns high and embedded low frequencies, are used with temporal phase unwrapping to compute absolute phase values in closed-form, without quantization or approximation via LUT, resulting in fast computation. The absolute phases provide correspondences from projector to camera pixels which enable to recover 3D points using optical triangulation. The algorithm estimates multiple absolute phase values per pixel which are combined to reduce measurement noise while preserving fine details. We prove that embedded periodic signals can be recovered from any periodic signal, not just sinusoidal signals, which may result in further improvements for other 3D imaging methods. Several experiments are presented showing that our algorithm produces more robust and accurate 3D scanning results than state-of-the-art methods for challenging surface materials, with an equal or smaller number of projected patterns and at lower computational cost.},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  doi = {10.1109/CVPR.2015.7298843},
  author = {Moreno, D. and Son, K. and Taubin, G.},
  month = jun,
  year = {2015},
  pages = {2301-2309},
  file = {/Users/markwang/DropBox (MIT)/zotero/Moreno et al_2015_Embedded phase shifting - Robust phase shifting with embedded signals.pdf}
}

@article{saldnerTemporalPhaseUnwrapping1997,
  title = {Temporal Phase Unwrapping: Application to Surface Profiling of Discontinuous Objects},
  volume = {36},
  issn = {0003-6935, 1539-4522},
  shorttitle = {Temporal Phase Unwrapping},
  language = {en},
  number = {13},
  journal = {Applied Optics},
  doi = {10.1364/AO.36.002770},
  author = {Saldner, H. O. and Huntley, J. M.},
  month = may,
  year = {1997},
  pages = {2770},
  file = {/Users/markwang/DropBox (MIT)/zotero/Saldner_Huntley_1997_Temporal phase unwrapping - application to surface profiling of discontinuous objects.pdf}
}

@article{dengParallelMultiBlockADMM2016,
  title = {Parallel {{Multi}}-{{Block ADMM}} with o(1 / k) {{Convergence}}},
  volume = {71},
  abstract = {This paper introduces a parallel and distributed algorithm for solving the following minimization problem with linear constraints},
  journal = {Journal of Scientific Computing},
  doi = {10.1007/s10915-016-0318-2},
  author = {Deng, Wei and Lai, Ming-Jun and Peng, Zhimin and Yin, Wotao},
  month = nov,
  year = {2016},
  file = {/Users/markwang/DropBox (MIT)/zotero/Deng et al_2016_Parallel Multi-Block ADMM with o(1 - k) Convergence.pdf}
}


@article{chenDirectExtensionADMM2016,
  title = {The Direct Extension of {{ADMM}} for Multi-Block Convex Minimization Problems Is Not Necessarily Convergent},
  volume = {155},
  issn = {1436-4646},
  abstract = {The alternating direction method of multipliers (ADMM) is now widely used in many fields, and its convergence was proved when two blocks of variables are alternatively updated. It is strongly desirable and practically valuable to extend the ADMM directly to the case of a multi-block convex minimization problem where its objective function is the sum of more than two separable convex functions. However, the convergence of this extension has been missing for a long time\textemdash{}neither an affirmative convergence proof nor an example showing its divergence is known in the literature. In this paper we give a negative answer to this long-standing open question: The direct extension of ADMM is not necessarily convergent. We present a sufficient condition to ensure the convergence of the direct extension of ADMM, and give an example to show its divergence.},
  language = {en},
  number = {1},
  journal = {Mathematical Programming},
  doi = {10.1007/s10107-014-0826-5},
  author = {Chen, Caihua and He, Bingsheng and Ye, Yinyu and Yuan, Xiaoming},
  month = jan,
  year = {2016},
  pages = {57-79},
  file = {/Users/markwang/DropBox (MIT)/zotero/Chen et al_2016_The direct extension of ADMM for multi-block convex minimization problems is not necessarily convergent.pdf}
}

@inproceedings{hongConvergenceAnalysisAlternating2015,
  title = {Convergence Analysis of Alternating Direction Method of Multipliers for a Family of Nonconvex Problems},
  abstract = {In this paper, we analyze the behavior of the alternating direction method of multipliers (ADMM), for solving a family of nonconvex problems. Our focus is given to the well-known consensus and sharing problems, both of which have wide applications in signal processing. We show that in the presence of nonconvex objective function, classical ADMM is able to reach the set of stationary solutions for these problems, if the stepsize is chosen large enough. An interesting consequence of our analysis is that the ADMM is convergent for a family of sharing problems, regardless of the number of blocks or the convexity of the objective function. Our analysis is broadly applicable to many ADMM variants involving proximal update rules and various flexible block selection rules.},
  booktitle = {2015 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  doi = {10.1109/ICASSP.2015.7178689},
  author = {Hong, M. and Luo, Z. and Razaviyayn, M.},
  month = apr,
  year = {2015},
  pages = {3836-3840},
  file = {/Users/markwang/DropBox (MIT)/zotero/Hong et al_2015_Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems.pdf}
}

@article{linGlobalLinearConvergence2015,
  title = {On the {{Global Linear Convergence}} of the {{ADMM}}  with {{MultiBlock Variables}}},
  volume = {25},
  issn = {1052-6234},
  abstract = {The alternating direction method of multipliers (ADMM) has been widely used for solving structured convex optimization problems. In particular, the ADMM can solve convex programs that minimize the sum of \$N\$ convex functions whose variables are linked by some linear constraints. While the convergence of the ADMM for \$N=2\$ was well established in the literature, it remained an open problem for a long time whether the ADMM for \$N \textbackslash{}ge 3\$ is still convergent. Recently, it was shown in [Chen et al., Math. Program. (2014), DOI 10.1007/s10107-014-0826-5.] that without additional conditions the ADMM for \$N\textbackslash{}ge 3\$ generally fails to converge. In this paper, we show that under some easily verifiable and reasonable  conditions the global linear convergence of the ADMM when \$N\textbackslash{}geq 3\$ can still be ensured, which is important since the ADMM is a popular method for solving large-scale multiblock optimization models and is known to perform very well in practice even when \$N\textbackslash{}ge 3\$. Our study aims to offer an explanation for this phenomenon.},
  number = {3},
  journal = {SIAM Journal on Optimization},
  doi = {10.1137/140971178},
  author = {Lin, Tianyi. and Ma, Shiqian. and Zhang, Shuzhong.},
  month = jan,
  year = {2015},
  pages = {1478-1497},
  file = {/Users/markwang/DropBox (MIT)/zotero/Lin et al_2015_On the Global Linear Convergence of the ADMM with MultiBlock Variables.pdf}
}

@article{hongLinearConvergenceAlternating2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1208.3922},
  primaryClass = {math, stat},
  title = {On the {{Linear Convergence}} of the {{Alternating Direction Method}} of {{Multipliers}}},
  abstract = {We analyze the convergence rate of the alternating direction method of multipliers (ADMM) for minimizing the sum of two or more nonsmooth convex separable functions subject to linear constraints. Previous analysis of the ADMM typically assumes that the objective function is the sum of only two convex functions defined on two separable blocks of variables even though the algorithm works well in numerical experiments for three or more blocks. Moreover, there has been no rate of convergence analysis for the ADMM without strong convexity in the objective function. In this paper we establish the global linear convergence of the ADMM for minimizing the sum of any number of convex separable functions. This result settles a key question regarding the convergence of the ADMM when the number of blocks is more than two or if the strong convexity is absent. It also implies the linear convergence of the ADMM for several contemporary applications including LASSO, Group LASSO and Sparse Group LASSO without any strong convexity assumption. Our proof is based on estimating the distance from a dual feasible solution to the optimal dual solution set by the norm of a certain proximal residual, and by requiring the dual stepsize to be sufficiently small.},
  journal = {arXiv:1208.3922 [math, stat]},
  author = {Hong, Mingyi and Luo, Zhi-Quan},
  month = aug,
  year = {2012},
  file = {/Users/markwang/DropBox (MIT)/zotero/Hong_Luo_2012_On the Linear Convergence of the Alternating Direction Method of Multipliers.pdf}
}


