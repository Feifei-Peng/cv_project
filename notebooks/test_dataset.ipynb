{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset for C2B camera\n",
    "\n",
    "+ 2019.06.05\n",
    "+ camera pattern (all 0 -> all light to bucket1)\n",
    "+ 4 projector patterns consisting of spatial sinusoids\n",
    "    + `Sinusoids-freq=04_bins=24_subframes=04/`\n",
    "    + 96 pattern images -> 24/frame\n",
    "+ 10 static scenes, (1000 frames/scene)\n",
    "+ 60 ms exposure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "import demosaicing as dm\n",
    "import importlib; importlib.reload(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdir = \"../data/exp60\"\n",
    "first_pattern_indices = [0,1,2,3]\n",
    "n_patterns = len(first_pattern_indices)\n",
    "n_frames_total = 1000\n",
    "n_frames_per_pattern = 250  # pick one myself\n",
    "assert(n_frames_per_pattern <= n_frames_total/n_patterns)\n",
    "imgsize = (176, 288)\n",
    "n_scenes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [x for x in os.listdir(topdir) if not x.startswith('.') and x != 'organized']\n",
    "scenes = scenes[:n_scenes]\n",
    "scenes = {k: f'{os.path.join(topdir, k)}/bucket1*.png' for k in scenes}\n",
    "scenes = {k: sorted(glob.glob(v)) for k,v in scenes.items()}\n",
    "assert(all([len(v) == n_frames_total for k,v in scenes.items()]))\n",
    "\n",
    "stacks = {k: None for k in scenes.keys()}\n",
    "for k,s in scenes.items():\n",
    "    \n",
    "    videos = np.zeros((len(s),*imgsize))\n",
    "    for i,imgpath in enumerate(s):\n",
    "        videos[i,:,:] = cv.imread(imgpath, cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # since images corresponding to patterns [0,1,2,3] not in order at some point\n",
    "    #     compute distance (frobenius norm) of images, and sort the frames by increasing distance metric\n",
    "    frame_distance = np.zeros((len(first_pattern_indices),len(s)))\n",
    "    for i in range(len(first_pattern_indices)):\n",
    "        for j in range(len(s)):\n",
    "            frame_distance[i,j] = np.linalg.norm(videos[i,:,:]-videos[j,:,:,],'fro')\n",
    "\n",
    "    frame_distance = frame_distance.argsort(axis=1)\n",
    "    frame_distance = {i: frame_distance[i,:] for i in first_pattern_indices}\n",
    "    #     {pattern_id: [idx_to_closest_img, indx_to_second_closest_img, ...]}\n",
    "    \n",
    "    \n",
    "    # now stack the first several for each pattern\n",
    "    #     (4, 176, 288, n_frames_per_pattern)\n",
    "    stack = np.zeros((n_patterns,*imgsize,n_frames_per_pattern), dtype=np.uint8)\n",
    "    for pattern_id,indices_to_sorted in frame_distance.items():\n",
    "        for j,imgidx in enumerate(indices_to_sorted[:n_frames_per_pattern]):\n",
    "            stack[pattern_id,:,:,j] = videos[imgidx,:,:]\n",
    "    \n",
    "    print(f'stacking [ {n_frames_per_pattern} images / {n_patterns} patterns ] for scene={k}')\n",
    "    stack = np.mean(stack/255., axis=3)\n",
    "    stack = (stack*255).astype(np.uint8)\n",
    "    stacks[k] = stack\n",
    "    #     {k: (4, 176, 288)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scene, stack in stacks.items():\n",
    "    imgs = [stack[i,:,:] for i in range(n_patterns)] + \\\n",
    "            [cv.imread(scenes['candle'][0], cv.IMREAD_GRAYSCALE)]\n",
    "\n",
    "    desc = [f'scene={scene} pattern={i}' for i in range(n_patterns)] + ['rand noisy']\n",
    "    show_grayscales(imgs, desc, layouts='15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene,stack in stacks.items():\n",
    "\n",
    "    outputdir = os.path.join(topdir,'organized')\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir, exist_ok=True)\n",
    "    print(f'outputing {n_patterns} stacked images for ({scene}) to [{outputdir}]')\n",
    "\n",
    "    for i in range(n_patterns):\n",
    "        cv.imwrite(os.path.join(outputdir, f'{scene}_{i}.png'), stack[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv_project] *",
   "language": "python",
   "name": "conda-env-cv_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
